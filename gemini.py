import json
import logging
import os
import html

from google import genai
from google.genai import types


# IMPORTANT: KEEP THIS COMMENT
# Follow these instructions when using this blueprint:
# - Note that the newest Gemini model series is "gemini-2.5-flash" or gemini-2.5-pro"
#   - do not change this unless explicitly requested by the user

# This API key is from Gemini Developer API Key, not vertex AI API Key
def get_gemini_client():
    """ุงูุญุตูู ุนูู ุนููู Gemini (ูุนูุฏ None ุฅุฐุง ูู ููุฌุฏ API key)"""
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        return None
    return genai.Client(api_key=api_key)


def answer_with_ai(question: str) -> dict:
    """
    ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุจุงุณุชุฎุฏุงู Gemini AI ุจุทุฑููุฉ ุฐููุฉ ูุจุงููุบุฉ ุงูุนุฑุจูุฉ.
    ูุนูุฏ dict ูุน 'text' ู 'html' ุฃู None ุฅุฐุง ูู ููู API key ูุชููุฑุงู.
    """
    try:
        client = get_gemini_client()
        if not client:
            return None
            
        # ุจูุงุก prompt ุฐูู ุจุงููุบุฉ ุงูุนุฑุจูุฉ
        system_prompt = """ุฃูุช "ุจุณุงู ุงูุฐูู" - ูุณุงุนุฏ ุฐูู ุนุฑุจู ูุชุฎุตุต ูู:
1. ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุจูุถูุญ ูุฏูุฉ ุจุงููุบุฉ ุงูุนุฑุจูุฉ
2. ุดุฑุญ ุงูููุงููู ุงูุนูููุฉ ูุงูุฑูุงุถูุฉ ุจุทุฑููุฉ ูุจุณุทุฉ
3. ุชูุฏูู ูุนูููุงุช ููุซููุฉ ููููุฏุฉ
4. ุงููุณุงุนุฏุฉ ูู ุญู ุงููุดุงูู ูุชูุฏูู ุงููุตุงุฆุญ

ููุงุนุฏ ูููุฉ:
- ุฃุฌุจ ุจุงููุบุฉ ุงูุนุฑุจูุฉ ุฏุงุฆูุงู
- ุงุฌุนู ุฅุฌุงุจุชู ูุงุถุญุฉ ูููุตูุฉ
- ุงุณุชุฎุฏู ุฃูุซูุฉ ุนูููุฉ ุนูุฏ ุงูุญุงุฌุฉ
- ุฅุฐุง ูู ุชุนุฑู ุงูุฅุฌุงุจุฉุ ูู ุฐูู ุจุตุฑุงุญุฉ
- ุชุฌูุจ ุงููุนูููุงุช ุงูุฎุงุทุฆุฉ ุฃู ุงููุถููุฉ"""

        prompt = f"{system_prompt}\n\nุงูุณุคุงู: {question}\n\nุงูุฅุฌุงุจุฉ:"
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=1000,
            )
        )

        if response.text:
            answer_text = response.text.strip()
            
            # ุชูุณูู HTML ููุฅุฌุงุจุฉ
            safe_question = html.escape(question)
            safe_answer = html.escape(answer_text)
            
            # ุชุญููู ุงูููุงุท ูุงูุฃุฑูุงู ุฅูู ุชูุณูู ุฃูุถู
            formatted_answer = safe_answer.replace('\n', '<br>')
            formatted_answer = formatted_answer.replace('- ', '<br>โข ')
            formatted_answer = formatted_answer.replace('. ', '.<br><br>')
            
            html_response = f'''
            <div class="card">
                <h4>๐ค ุฅุฌุงุจุฉ ุจุณุงู ุงูุฐูู</h4>
                <h5 style="color:#666;">โ ุงูุณุคุงู: {safe_question}</h5>
                <hr>
                <div style="background:#f9f9f9;padding:15px;border-radius:8px;line-height:1.6;">
                    {formatted_answer}
                </div>
                <small style="color:#999;margin-top:10px;display:block;">
                    ๐ก ุชู ุชูููุฏ ูุฐู ุงูุฅุฌุงุจุฉ ุจูุงุณุทุฉ Gemini AI
                </small>
            </div>
            '''
            
            return {
                "text": answer_text, 
                "html": html_response
            }
        else:
            return None
            
    except Exception as e:
        logging.error(f"ุฎุทุฃ ูู Gemini AI: {e}")
        error_html = f'''
        <div class="card" style="border-left:4px solid #ff6b6b;">
            <h4>โ ุฎุทุฃ ูู ูุธุงู ุงูุฐูุงุก ุงูุงุตุทูุงุนู</h4>
            <p>ุนุฐุฑุงูุ ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ูุนุงูุฌุฉ ุณุคุงูู. ูุฑุฌู ุงููุญุงููุฉ ูุฑุฉ ุฃุฎุฑู.</p>
            <small style="color:#666;">ุชูุงุตูู ุงูุฎุทุฃ: {html.escape(str(e))}</small>
        </div>
        '''
        return {
            "text": f"ุฎุทุฃ ูู AI: {str(e)}", 
            "html": error_html
        }


def smart_math_help(question: str) -> dict:
    """
    ูุณุงุนุฏุฉ ุฐููุฉ ูู ุงูุฑูุงุถูุงุช ุจุงุณุชุฎุฏุงู Gemini
    """
    try:
        client = get_gemini_client()
        if not client:
            return None
            
        system_prompt = """ุฃูุช ูุฏุฑุณ ุฑูุงุถูุงุช ุฎุจูุฑ. ุงุดุฑุญ ุงูุญููู ุงูุฑูุงุถูุฉ ุฎุทูุฉ ุจุฎุทูุฉ ุจุงููุบุฉ ุงูุนุฑุจูุฉ.

ููุงุนุฏ ูููุฉ:
- ุงุดุฑุญ ูู ุฎุทูุฉ ุจูุถูุญ
- ุงุณุชุฎุฏู ุงูุฃุฑูุงู ูุงูุฑููุฒ ุงูุฑูุงุถูุฉ
- ูุฏู ุฃูุซูุฉ ูุดุงุจูุฉ ุฅุฐุง ุฃููู
- ุชุฃูุฏ ูู ุฏูุฉ ุงูุญุณุงุจุงุช"""

        prompt = f"{system_prompt}\n\nุงูุณุคุงู ุงูุฑูุงุถู: {question}\n\nุงูุญู ุงูุชูุตููู:"
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt
        )

        if response.text:
            answer_text = response.text.strip()
            safe_answer = html.escape(answer_text)
            formatted_answer = safe_answer.replace('\n', '<br>')
            
            html_response = f'''
            <div class="card">
                <h4>๐งฎ ูุณุงุนุฏ ุงูุฑูุงุถูุงุช ุงูุฐูู</h4>
                <hr>
                <div style="background:#f0f8ff;padding:15px;border-radius:8px;line-height:1.8;">
                    {formatted_answer}
                </div>
            </div>
            '''
            
            return {
                "text": answer_text, 
                "html": html_response
            }
        else:
            return None
            
    except Exception as e:
        logging.error(f"ุฎุทุฃ ูู ูุณุงุนุฏ ุงูุฑูุงุถูุงุช: {e}")
        return None


def is_gemini_available() -> bool:
    """ูุญุต ุชููุฑ Gemini API"""
    return os.environ.get("GEMINI_API_KEY") is not None