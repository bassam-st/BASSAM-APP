# main.py â€” Ø¨Ø­Ø« Ø¹Ø±Ø¨ÙŠ Ù…Ø¬Ø§Ù†ÙŠ + ØªÙ„Ø®ÙŠØµ Ø°ÙƒÙŠ + Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…ØªØ§Ø¬Ø± + ØµÙˆØ± + ØªÙ‚ÙŠÙŠÙ… + PDF + Ù†Ø³Ø® + ÙˆØ¶Ø¹ Ù„ÙŠÙ„ÙŠ
from fastapi import FastAPI, Form, Request, Response
from fastapi.responses import HTMLResponse, JSONResponse
from ddgs import DDGS
from readability import Document
from bs4 import BeautifulSoup
from diskcache import Cache
from urllib.parse import urlparse, urlencode
from fpdf import FPDF
import requests, re, html, time

app = FastAPI()
cache = Cache(".cache")

# ---------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ----------------
PREFERRED_AR_DOMAINS = {
    "ar.wikipedia.org", "ar.m.wikipedia.org",
    "mawdoo3.com", "almrsal.com", "sasapost.com",
    "arabic.cnn.com", "bbcarabic.com", "aljazeera.net",
    "ar.wikihow.com", "moe.gov.sa", "yemen.gov.ye", "moh.gov.sa"
}

MARKET_SITES = [
    "alibaba.com", "1688.com", "aliexpress.com",
    "amazon.com", "amazon.ae", "amazon.sa", "amazon.eg",
    "noon.com", "jumia.com", "jumia.com.eg",
    "ebay.com", "made-in-china.com", "temu.com", "souq.com"
]

HDRS = {"User-Agent": "Mozilla/5.0 (compatible; BassamBot/1.2)"}

# -------- Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† --------
# ÙƒÙ„Ù…Ø§Øª Ù…Ù†Ø§Ø³Ø¨Ø© Ø·Ø¨ÙŠØ§Ù‹/ØªØ¹Ù„ÙŠÙ…ÙŠØ§Ù‹/Ø¯ÙŠÙ†ÙŠØ§Ù‹
EDUCATIONAL_CONTEXTS = {
    # Ø³ÙŠØ§Ù‚ Ø·Ø¨ÙŠ
    'Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ø«Ø¯ÙŠ', 'Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ù‚Ø¶ÙŠØ¨', 'Ø±Ø¶Ø§Ø¹Ø© Ø·Ø¨ÙŠØ¹ÙŠØ©', 'ÙØ­Øµ Ø·Ø¨ÙŠ', 'ØªØ«Ù‚ÙŠÙ Ø¬Ù†Ø³ÙŠ', 'ØµØ­Ø© Ø§Ù„Ù…Ø±Ø£Ø©',
    'Ø£Ø¹Ø±Ø§Ø¶', 'Ø¹Ù„Ø§Ø¬', 'Ø·Ø¨', 'ØµØ­Ø©', 'ØªØ´Ø±ÙŠØ­', 'Ø§Ù„ØªÙ‡Ø§Ø¨', 'Ù…Ø±Ø¶', 'Ø¯ÙˆØ§Ø¡',
    'breast cancer', 'breastfeeding', 'medical exam', 'sex education', 'reproductive health',
    'symptoms', 'treatment', 'medicine', 'health', 'anatomy', 'inflammation', 'disease',
    
    # Ø³ÙŠØ§Ù‚ Ø¯ÙŠÙ†ÙŠ/ØªØ¹Ù„ÙŠÙ…ÙŠ
    'Ø­ÙƒÙ… Ø§Ù„Ø²Ù†Ø§', 'Ø­Ø¯ Ø§Ù„Ø²Ù†Ø§', 'ÙÙ‚Ù‡', 'Ø¯ÙŠÙ†', 'Ø´Ø±ÙŠØ¹Ø©', 'Ø¥Ø³Ù„Ø§Ù…', 'Ø£Ø­ÙƒØ§Ù…', 'Ø­Ø¯ÙˆØ¯',
    'ØªØ¹Ù„ÙŠÙ…', 'Ø¯Ø±Ø³', 'Ø´Ø±Ø­', 'Ø¨Ø­Ø«', 'Ø¯Ø±Ø§Ø³Ø©', 'ÙƒØªØ§Ø¨', 'Ù…Ù‚Ø§Ù„', 'Ù…ÙˆØ³ÙˆØ¹Ø©',
    'islamic ruling', 'religious education', 'study', 'research', 'lesson', 'encyclopedia'
}

# Ø£Ù†Ù…Ø§Ø· Ù…Ø­Ø¸ÙˆØ±Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ Ø­Ø¯ÙˆØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
PROHIBITED_PATTERNS = [
    # Ø£Ù†Ù…Ø§Ø· Ø¹Ø±Ø¨ÙŠØ© (ÙƒÙ„Ù…Ø§Øª ÙƒØ§Ù…Ù„Ø© ÙÙ‚Ø·)
    r'\b(Ø¥Ø¨Ø§Ø­ÙŠ|Ø¥Ø¨Ø§Ø­ÙŠØ©|Ø¹Ø§Ù‡Ø±Ø©|Ø¹Ø§Ù‡Ø±Ø§Øª|Ø¯Ø¹Ø§Ø±Ø©|Ø´Ø°ÙˆØ°|Ø²Ù†Ø§|Ø¨ØºØ§Ø¡|ÙØ§Ø­Ø´Ø©)\b',
    r'\b(Ù†ÙŠÙƒ|Ù†ÙƒØ­|Ù„Ø­Ø³|Ù‚Ø¶ÙŠØ¨|ÙØ±Ø¬|Ø·ÙŠØ²|Ø¨Ø²Ø§Ø²)\b',
    r'\b(Ø¨ÙˆØ±Ù†|Ø³ÙƒØ³|Ø¹Ø§Ø±ÙŠ|Ø¹Ø§Ø±ÙŠØ©|ÙØ§Ø¶Ø­|ÙØ§Ø¶Ø­Ø©)\b',
    
    # Ø£Ù†Ù…Ø§Ø· Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ø¹ Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„ØªØ¬Ø§ÙˆØ²  
    r'\b(porn|xxx|fuck|nude|naked|sexy)\b',
    r'\b(prostitute|whore|penis|vagina|orgasm|erotic|fetish)\b',
    r'\b(masturbat\w*)\b',
    
    # Ø£Ù†Ù…Ø§Ø· Ù…Ù‚Ø§ÙˆÙ…Ø© Ù„Ù„ØªØ¬Ø§ÙˆØ²
    r's[\W_]*e[\W_]*x(?!tant|agesimal)',  # sex Ù„ÙƒÙ† Ù„ÙŠØ³ sextant
    r'p[\W_]*o[\W_]*r[\W_]*n',
    r'Ø¬[\W_Ù€]*Ù†[\W_Ù€]*Ø³',
    r'Ø³[\W_Ù€]*Ùƒ[\W_Ù€]*Ø³',
]

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø© Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
PROHIBITED_REGEX = re.compile('|'.join(PROHIBITED_PATTERNS), re.IGNORECASE | re.UNICODE)

def normalize_text(text: str) -> str:
    """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ù„Ø¥Ø²Ø§Ù„Ø© Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„ØªØ¬Ø§ÙˆØ²"""
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ ÙˆØ§Ù„Ø·Ø§ÙˆÙ„Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    text = re.sub(r'[\u064B-\u065F\u0670\u0640]', '', text)
    # ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ø£Ø­Ø±Ù Ø§Ù„ØµØºÙŠØ±Ø© ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    text = re.sub(r'\s+', ' ', text.lower().strip())
    # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… ÙˆØ§Ù„Ø±Ù…ÙˆØ²
    text = re.sub(r'[^\w\s]', ' ', text)
    return text

def is_inappropriate_content(text: str) -> bool:
    """ÙØ­Øµ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù…Ø¹ ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø§Ù„Ø®Ø§Ø·Ø¦Ø©"""
    if not text or len(text.strip()) < 3:
        return False
    
    # ÙØ­Øµ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ/Ø§Ù„Ø·Ø¨ÙŠ Ø£ÙˆÙ„Ø§Ù‹
    text_lower = text.lower()
    for context in EDUCATIONAL_CONTEXTS:
        if context in text_lower:
            return False  # Ù…Ø­ØªÙˆÙ‰ ØªØ¹Ù„ÙŠÙ…ÙŠ/Ø·Ø¨ÙŠ Ù…Ù‚Ø¨ÙˆÙ„
    
    # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„ØªØ¬Ø§ÙˆØ²
    normalized_text = normalize_text(text)
    
    # ÙØ­Øµ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©
    if PROHIBITED_REGEX.search(normalized_text):
        return True
    
    return False

def get_reminder_message() -> str:
    """Ø±Ø³Ø§Ù„Ø© ØªØ°ÙƒÙŠØ±ÙŠØ© Ù…Ù‡Ø°Ø¨Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    return '''
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                color: white; padding: 20px; border-radius: 10px; text-align: center; margin: 20px 0;">
        <h3>ğŸ•Œ ØªØ°ÙƒÙŠØ± Ø£Ø®ÙˆÙŠ ÙƒØ±ÙŠÙ…</h3>
        <p style="font-size: 16px; line-height: 1.6;">
            Ø£Ø®ÙŠ Ø§Ù„ÙƒØ±ÙŠÙ…ØŒ Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ Ù…Ø®ØµØµ Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙÙŠØ¯Ø© ÙˆØ§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù†Ø§ÙØ¹Ø©.<br>
            ØªØ°ÙƒØ± Ø£Ù† Ø§Ù„Ù„Ù‡ ÙŠØ±Ø§Ùƒ ÙˆÙŠØ³Ù…Ø¹Ùƒ ÙÙŠ ÙƒÙ„ ÙˆÙ‚Øª.<br>
            <strong>"ÙˆÙØ§Ø¹Ù’Ù„ÙÙ…ÙÙˆØ§ Ø£ÙÙ†ÙÙ‘ Ø§Ù„Ù„ÙÙ‘Ù‡Ù ÙŠÙØ¹Ù’Ù„ÙÙ…Ù Ù…ÙØ§ ÙÙÙŠ Ø£ÙÙ†ÙÙØ³ÙÙƒÙÙ…Ù’ ÙÙØ§Ø­Ù’Ø°ÙØ±ÙÙˆÙ‡Ù"</strong>
        </p>
        <p style="margin-top: 15px;">
            ğŸŒŸ Ø§Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ù…ÙÙŠØ¯Ø© Ø¹Ù† Ø§Ù„Ø¹Ù„ÙˆÙ…ØŒ Ø§Ù„ØªÙ‚Ù†ÙŠØ©ØŒ Ø§Ù„Ø¯ÙŠÙ†ØŒ Ø§Ù„ØªØ§Ø±ÙŠØ®ØŒ Ø£Ùˆ Ø£ÙŠ Ù…ÙˆØ¶ÙˆØ¹ ÙŠÙÙŠØ¯Ùƒ ÙˆÙŠÙÙŠØ¯ Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†
        </p>
    </div>
    '''

# -------- Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù„ØºØ© ÙˆØ§Ù„Ù…Ù„Ø®Øµ --------
AR_RE = re.compile(r"[Ø§Ø£Ø¥Ø¢Ø¡-ÙŠ]")
def is_arabic(text: str, min_ar_chars: int = 30) -> bool:
    return len(AR_RE.findall(text or "")) >= min_ar_chars

# -------- Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© --------
class SmartAnswerEngine:
    def __init__(self):
        self.question_types = {
            'Ù…Ø§ Ù‡Ùˆ': 'definition',
            'Ù…Ø§ Ù‡ÙŠ': 'definition', 
            'ÙƒÙŠÙ': 'how_to',
            'Ù„Ù…Ø§Ø°Ø§': 'why',
            'Ù…ØªÙ‰': 'when',
            'Ø£ÙŠÙ†': 'where',
            'Ù…Ù†': 'who',
            'ÙƒÙ…': 'quantity',
            'Ù‡Ù„': 'yes_no'
        }
        
    def analyze_question(self, question: str):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„ÙÙ‡Ù… Ù†ÙˆØ¹Ù‡ ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        question_lower = question.strip().lower()
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
        question_type = 'general'
        for keyword, qtype in self.question_types.items():
            if question_lower.startswith(keyword):
                question_type = qtype
                break
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        keywords = self.extract_keywords(question)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ­ØªØ§Ø¬ ØªÙØµÙŠÙ„
        needs_detail = any(word in question_lower for word in ['Ø§Ø´Ø±Ø­', 'ÙØµÙ„', 'ÙˆØ¶Ø­', 'Ø¨Ø§Ù„ØªÙØµÙŠÙ„'])
        
        return {
            'type': question_type,
            'keywords': keywords,
            'needs_detail': needs_detail,
            'original': question
        }
    
    def extract_keywords(self, text: str):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ"""
        # Ø¥Ø²Ø§Ù„Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… ÙˆØ­Ø±ÙˆÙ Ø§Ù„Ø¬Ø±
        stop_words = {'Ù…Ø§', 'Ù‡Ùˆ', 'Ù‡ÙŠ', 'ÙƒÙŠÙ', 'Ù„Ù…Ø§Ø°Ø§', 'Ù…ØªÙ‰', 'Ø£ÙŠÙ†', 'Ù…Ù†', 'ÙƒÙ…', 'Ù‡Ù„', 
                     'ÙÙŠ', 'Ø¹Ù„Ù‰', 'Ø¥Ù„Ù‰', 'Ù…Ù†', 'Ø¹Ù†', 'Ù…Ø¹', 'Ø¶Ø¯', 'ØªØ­Øª', 'ÙÙˆÙ‚'}
        
        words = text.split()
        keywords = [word.strip('ØŸØŒ.!') for word in words if word not in stop_words and len(word) > 2]
        return keywords[:5]  # Ø£Ù‡Ù… 5 ÙƒÙ„Ù…Ø§Øª
        
    def generate_smart_answer(self, question_analysis, search_results, detailed=False):
        """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ø°ÙƒÙŠØ© Ù…Ø®ØªØµØ±Ø© Ù…Ù† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«"""
        if not search_results:
            return "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø³Ø¤Ø§Ù„Ùƒ. Ø­Ø§ÙˆÙ„ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„."
            
        # Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±
        all_content = []
        sources = []
        
        for result in search_results:
            if result.get('content'):
                all_content.append(result['content'])
                sources.append(result.get('title', 'Ù…ØµØ¯Ø±'))
        
        if not all_content:
            return "Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ."
        
        # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø©
        answer = self.create_targeted_answer(question_analysis, all_content, detailed)
        
        # Ø¥Ø¶Ø§ÙØ© Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
        if len(sources) > 0:
            source_list = ", ".join(sources[:3])  # Ø£ÙˆÙ„ 3 Ù…ØµØ§Ø¯Ø±
            answer += f"\n\nØ§Ù„Ù…ØµØ§Ø¯Ø±: {source_list}"
            
        return answer
    
    def create_targeted_answer(self, analysis, content_list, detailed):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø³ØªÙ‡Ø¯ÙØ© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„"""
        combined_content = " ".join(content_list)
        question_type = analysis['type']
        
        if question_type == 'definition':
            return self.answer_definition(combined_content, detailed)
        elif question_type == 'how_to':
            return self.answer_how_to(combined_content, detailed)
        elif question_type == 'why':
            return self.answer_why(combined_content, detailed)
        elif question_type == 'when':
            return self.answer_when(combined_content, detailed)
        elif question_type == 'where':
            return self.answer_where(combined_content, detailed)
        elif question_type == 'who':
            return self.answer_who(combined_content, detailed)
        else:
            return self.answer_general(combined_content, detailed)
    
    def answer_definition(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ¹Ø±ÙŠÙ (Ù…Ø§ Ù‡Ùˆ/Ù…Ø§ Ù‡ÙŠ)"""
        sentences = self.split_into_sentences(content)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…Ù„ Ø§Ù„ØªØ¹Ø±ÙŠÙ
        definition_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['Ù‡Ùˆ', 'Ù‡ÙŠ', 'ÙŠØ¹Ø±Ù', 'ÙŠÙØ¹Ø±Ù‘Ù', 'Ù…ØµØ·Ù„Ø­', 'Ù…ÙÙ‡ÙˆÙ…']):
                definition_sentences.append(sentence)
        
        if not definition_sentences:
            definition_sentences = sentences[:2]  # Ø£ÙˆÙ„ Ø¬Ù…Ù„ØªÙŠÙ†
        
        if detailed:
            return " ".join(definition_sentences[:4])  # 4 Ø¬Ù…Ù„ Ù„Ù„ØªÙØµÙŠÙ„
        else:
            return definition_sentences[0] if definition_sentences else sentences[0]
    
    def answer_how_to(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© (ÙƒÙŠÙ)"""
        sentences = self.split_into_sentences(content)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…Ù„ Ø§Ù„Ø®Ø·ÙˆØ§Øª ÙˆØ§Ù„Ø·Ø±Ù‚
        how_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['Ø®Ø·ÙˆØ©', 'Ø·Ø±ÙŠÙ‚Ø©', 'ÙƒÙŠÙÙŠØ©', 'ÙŠÙ…ÙƒÙ†', 'Ø£ÙˆÙ„Ø§Ù‹', 'Ø«Ø§Ù†ÙŠØ§Ù‹', 'Ø¹Ø¨Ø±', 'Ù…Ù† Ø®Ù„Ø§Ù„']):
                how_sentences.append(sentence)
        
        if not how_sentences:
            how_sentences = sentences[:3]
        
        if detailed:
            return " ".join(how_sentences[:5])
        else:
            return " ".join(how_sentences[:2])
    
    def answer_why(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø³Ø¨Ø¨ (Ù„Ù…Ø§Ø°Ø§)"""
        sentences = self.split_into_sentences(content)
        
        why_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['Ø³Ø¨Ø¨', 'Ù„Ø£Ù†', 'Ù†ØªÙŠØ¬Ø©', 'Ø¨Ø³Ø¨Ø¨', 'ÙŠØ¤Ø¯ÙŠ', 'ÙŠØ³Ø¨Ø¨', 'Ø§Ù„Ø³Ø¨Ø¨']):
                why_sentences.append(sentence)
        
        if not why_sentences:
            why_sentences = sentences[:2]
        
        if detailed:
            return " ".join(why_sentences[:4])
        else:
            return why_sentences[0] if why_sentences else sentences[0]
    
    def answer_when(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙˆÙ‚Øª (Ù…ØªÙ‰)"""
        sentences = self.split_into_sentences(content)
        
        when_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['Ø¹Ø§Ù…', 'ØªØ§Ø±ÙŠØ®', 'ÙŠÙˆÙ…', 'Ø´Ù‡Ø±', 'Ù‚Ø¨Ù„', 'Ø¨Ø¹Ø¯', 'ÙÙŠ', 'Ù…Ù†Ø°']):
                when_sentences.append(sentence)
        
        if not when_sentences:
            when_sentences = sentences[:2]
        
        return " ".join(when_sentences[:3 if detailed else 1])
    
    def answer_where(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ§Ù† (Ø£ÙŠÙ†)"""
        sentences = self.split_into_sentences(content)
        
        where_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['ÙÙŠ', 'Ø¨Ù€', 'ØªÙ‚Ø¹', 'ÙŠÙ‚Ø¹', 'Ù…ÙˆÙ‚Ø¹', 'Ù…ÙƒØ§Ù†', 'Ø¯ÙˆÙ„Ø©', 'Ù…Ø¯ÙŠÙ†Ø©']):
                where_sentences.append(sentence)
        
        if not where_sentences:
            where_sentences = sentences[:2]
        
        return " ".join(where_sentences[:3 if detailed else 1])
    
    def answer_who(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù‡ÙˆÙŠØ© (Ù…Ù†)"""
        sentences = self.split_into_sentences(content)
        
        who_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['Ø´Ø®Øµ', 'Ø±Ø¬Ù„', 'Ø§Ù…Ø±Ø£Ø©', 'Ø¹Ø§Ù„Ù…', 'Ù…Ø¤Ù„Ù', 'Ø±Ø¦ÙŠØ³', 'Ù…Ø¯ÙŠØ±']):
                who_sentences.append(sentence)
        
        if not who_sentences:
            who_sentences = sentences[:2]
        
        return " ".join(who_sentences[:3 if detailed else 1])
    
    def answer_general(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ø§Ù…Ø© Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø£Ø®Ø±Ù‰"""
        sentences = self.split_into_sentences(content)
        
        if detailed:
            return " ".join(sentences[:5])
        else:
            return " ".join(sentences[:2])
    
    def split_into_sentences(self, text):
        """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø¬Ù…Ù„"""
        sentences = re.split(r'[.!ØŸ\?\n]+', text)
        clean_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 20:  # Ø¬Ù…Ù„ Ø°Ø§Øª Ù…Ø¹Ù†Ù‰
                clean_sentences.append(sentence)
        return clean_sentences[:10]  # Ø£ÙˆÙ„ 10 Ø¬Ù…Ù„ ÙÙ‚Ø·

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒÙŠØ©
smart_engine = SmartAnswerEngine()

STOP = set("""Ù…Ù† ÙÙŠ Ø¹Ù„Ù‰ Ø¥Ù„Ù‰ Ø¹Ù† Ø£Ù† Ø¥Ù† Ø¨Ø£Ù† ÙƒØ§Ù† ØªÙƒÙˆÙ† ÙŠÙƒÙˆÙ† Ø§Ù„ØªÙŠ Ø§Ù„Ø°ÙŠ Ø§Ù„Ø°ÙŠÙ† Ù‡Ø°Ø§ Ù‡Ø°Ù‡ Ø°Ù„Ùƒ Ù‡Ù†Ø§Ùƒ Ø«Ù… Ø­ÙŠØ« ÙƒÙ…Ø§ Ø§Ø°Ø§ Ø¥Ø°Ø§ Ø£Ùˆ Ùˆ ÙŠØ§ Ù…Ø§ Ù…Ø¹ Ù‚Ø¯ Ù„Ù… Ù„Ù† Ø¨ÙŠÙ† Ù„Ø¯Ù‰ Ù„Ø¯Ù‰ØŒ Ø¹Ù†Ø¯ Ø¨Ø¹Ø¯ Ù‚Ø¨Ù„ Ø¯ÙˆÙ† ØºÙŠØ± Ø­ØªÙ‰ ÙƒÙ„ Ø£ÙŠ ÙƒÙŠÙ Ù„Ù…Ø§Ø°Ø§ Ù…ØªÙ‰ Ù‡Ù„ Ø§Ù„Ù‰ Ø§Ù„""".split())

def tokenize(s: str):
    s = re.sub(r"[^\w\s\u0600-\u06FF]+", " ", s.lower())
    toks = [t for t in s.split() if t and t not in STOP]
    return toks

def score_sentences(text: str, query: str):
    sentences = re.split(r'(?<=[\.\!\?\ØŸ])\s+|\n+', text or "")
    q_terms = set(tokenize(query))
    scored = []
    for s in sentences:
        s2 = s.strip()
        if len(s2) < 25 or not is_arabic(s2, 8):
            continue
        terms = set(tokenize(s2))
        inter = q_terms & terms
        score = len(inter) + (len(s2) >= 80)
        if score > 0:
            scored.append((score, s2))
    scored.sort(reverse=True, key=lambda x: x[0])
    return [s for _, s in scored[:8]]

def summarize_from_text(text: str, query: str, max_sentences=3):
    sents = score_sentences(text, query)
    return " ".join(sents[:max_sentences]) if sents else ""

def domain_of(url: str):
    try:
        return urlparse(url).netloc.lower()
    except:
        return url

# -------- Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª (ØªØ¹Ù„Ù… Ø°Ø§ØªÙŠ Ø¨Ø³ÙŠØ·) --------
def get_scores():
    result = cache.get("domain_scores", {})
    return result if isinstance(result, dict) else {}

def save_scores(scores):
    cache.set("domain_scores", scores, expire=0)

def bump_score(domain: str, delta: int):
    if not domain:
        return
    scores = get_scores()
    scores[domain] = scores.get(domain, 0) + delta
    save_scores(scores)

# -------- Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø§Øª --------
def fetch(url: str, timeout=3):
    r = requests.get(url, headers=HDRS, timeout=timeout)
    r.raise_for_status()
    return r.text

def fetch_and_extract(url: str, timeout=2):
    try:
        html_text = fetch(url, timeout=timeout)
        if not html_text or len(html_text.strip()) < 100:
            return "", ""
        
        # ØªÙ†Ø¸ÙŠÙ HTML Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¶Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        html_text = html_text.replace('\x00', '').replace('\x0b', '').replace('\x0c', '')
        html_text = ''.join(char for char in html_text if ord(char) >= 32 or char in '\n\r\t')
        
        try:
            doc = Document(html_text)
            content_html = doc.summary()
        except:
            # Ø¥Ø°Ø§ ÙØ´Ù„ readabilityØŒ Ø§Ø³ØªØ®Ø¯Ù… BeautifulSoup Ù…Ø¨Ø§Ø´Ø±Ø©
            soup = BeautifulSoup(html_text, "html.parser")
            # Ø£Ø®Ø° Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ÙÙ‚Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            content = soup.find_all(['p', 'article', 'div'], limit=10)
            content_html = ''.join(str(tag) for tag in content)
        
        soup = BeautifulSoup(content_html, "html.parser")
        text = soup.get_text(separator="\n")
        return html.unescape(text), html_text
    except Exception as e:
        print(f"error getting summary: {e}")
        return "", ""

# -------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± --------
PRICE_RE = re.compile(r"(?i)(US?\s*\$|USD|EUR|GBP|AED|SAR|EGP|QAR|KWD|OMR|Ø¯\.Ø¥|Ø±\.Ø³|Ø¬\.Ù…|Ø¯\.Ùƒ|Ø±\.Ù‚|Ø±\.Ø¹)\s*[\d\.,]+")
AR_NUM = str.maketrans("Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©", "0123456789")

def extract_price_from_html(html_text: str):
    if not html_text:
        return ""
    text = BeautifulSoup(html_text, "html.parser").get_text(separator=" ")
    text = text.translate(AR_NUM)
    m = PRICE_RE.search(text)
    return m.group(0).strip() if m else ""

def try_get_price(url: str):
    try:
        h = fetch(url, timeout=3)
        price = extract_price_from_html(h)
        if price:
            return price
        soup = BeautifulSoup(h, "html.parser")
        meta_price = soup.find(attrs={"itemprop": "price"}) or soup.find("meta", {"property":"product:price:amount"})
        if meta_price:
            val = ""
            if hasattr(meta_price, 'get') and meta_price.get("content"):
                val = meta_price.get("content")
            elif hasattr(meta_price, 'text') and meta_price.text:
                val = meta_price.text
            if val and re.search(r"[\d\.,]", str(val)):
                return str(val).strip()
        time.sleep(0.3)
        h2 = fetch(url, timeout=3)
        return extract_price_from_html(h2)
    except Exception:
        return ""

# ---------------- ÙˆØ§Ø¬Ù‡Ø© HTML ----------------
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="ar" dir="rtl" data-theme="light">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no, viewport-fit=cover"/>
  <title>Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ - Ù…Ø¬Ø§Ù†ÙŠ</title>
  
  <!-- PWA Meta Tags -->
  <meta name="application-name" content="Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ"/>
  <meta name="description" content="Ù…Ø­Ø±Ùƒ Ø¨Ø­Ø« Ø°ÙƒÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø¬Ø§Ù†ÙŠØ© ÙˆØªÙ„Ø®ÙŠØµ ÙÙˆØ±ÙŠ"/>
  <meta name="theme-color" content="#4a90e2"/>
  <meta name="background-color" content="#ffffff"/>
  <meta name="mobile-web-app-capable" content="yes"/>
  <meta name="apple-mobile-web-app-capable" content="yes"/>
  <meta name="apple-mobile-web-app-status-bar-style" content="default"/>
  <meta name="apple-mobile-web-app-title" content="Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ"/>
  <meta name="msapplication-TileColor" content="#4a90e2"/>
  <meta name="msapplication-tap-highlight" content="no"/>
  
  <!-- PWA Manifest -->
  <link rel="manifest" href="/manifest.json"/>
  
  <!-- Apple Touch Icons -->
  <link rel="apple-touch-icon" href="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTkyIiBoZWlnaHQ9IjE5MiIgdmlld0JveD0iMCAwIDE5MiAxOTIiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PGNpcmNsZSBjeD0iOTYiIGN5PSI5NiIgcj0iOTYiIGZpbGw9IiM0YTkwZTIiLz48dGV4dCB4PSI5NiIgeT0iMTEwIiBmaWxsPSJ3aGl0ZSIgZm9udC1zaXplPSI2NCIgZm9udC1mYW1pbHk9IkFyaWFsIiB0ZXh0LWFuY2hvcj0ibWlkZGxlIj7YqDwvdGV4dD48L3N2Zz4="/>
  
  <!-- Favicon -->
  <link rel="icon" type="image/svg+xml" href="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48Y2lyY2xlIGN4PSIxNiIgY3k9IjE2IiByPSIxNiIgZmlsbD0iIzRhOTBlMiIvPjx0ZXh0IHg9IjE2IiB5PSIyMCIgZmlsbD0id2hpdGUiIGZvbnQtc2l6ZT0iMTYiIGZvbnQtZmFtaWx5PSJBcmlhbCIgdGV4dC1hbmNob3I9Im1pZGRsZSI+2KI8L3RleHQ+PC9zdmc+"/>
  <style>
    :root {{
      --bg:#ffffff; --fg:#111; --muted:#666; --card:#f7f7f7; --accent:#0b63c6; --summary:#eef6ff;
    }}
    [data-theme="dark"] {{
      --bg:#0f172a; --fg:#e5e7eb; --muted:#9ca3af; --card:#111827; --accent:#60a5fa; --summary:#0b2942;
    }}
    body {{ background:var(--bg); color:var(--fg); font-family: Tahoma, Arial; padding:18px; max-width:960px; margin:auto; }}
    input[type=text], select {{ width:100%; padding:12px; font-size:16px; background:var(--card); color:var(--fg); border:1px solid #334155; border-radius:10px; }}
    button {{ padding:10px 18px; font-size:16px; margin-top:8px; border-radius:10px; border:1px solid #334155; background:var(--card); color:var(--fg); cursor:pointer; }}
    .row {{ display:flex; gap:10px; flex-wrap:wrap; }}
    .col {{ flex:1 1 200px; min-width:220px; }}
    .card {{ background:var(--card); padding:12px; border-radius:10px; }}
    .summary {{ background:var(--summary); padding:12px; border-radius:10px; margin-top:10px; }}
    a {{ color:var(--accent); text-decoration:none; }}
    h1 {{ margin-top:0; }}
    .note {{ color:var(--muted); font-size:13px; }}
    .fb {{ display:inline-flex; gap:8px; margin-top:8px; }}
    .btn-mini {{ padding:6px 10px; font-size:13px; border:1px solid #334155; border-radius:8px; background:var(--bg); color:var(--fg); cursor:pointer; }}
    .toolbar {{ display:flex; gap:10px; align-items:center; flex-wrap:wrap; }}
    .imggrid {{ display:grid; grid-template-columns: repeat(auto-fill, minmax(140px, 1fr)); gap:10px; }}
    .imgcard {{ overflow:hidden; border-radius:10px; border:1px solid #334155; }}
    .imgcard img {{ width:100%; height:140px; object-fit:cover; display:block; }}
    .smart-answer {{ background:linear-gradient(135deg, var(--summary), var(--card)); border-left:4px solid var(--accent); font-weight:500; }}
    .btn-detail {{ background:var(--accent); color:white; padding:8px 16px; border-radius:8px; border:none; margin-top:10px; cursor:pointer; }}
    .btn-detail:hover {{ opacity:0.8; }}
    
    /* PWA & Mobile Optimizations */
    @media (max-width: 768px) {{
      body {{ padding: 12px; }}
      .row {{ flex-direction: column; }}
      .col {{ min-width: auto; }}
      input[type=text], select {{ font-size: 16px; padding: 14px; }}
      button {{ padding: 12px 20px; font-size: 16px; }}
      h1 {{ font-size: 1.5rem; }}
      .toolbar {{ flex-direction: column; align-items: stretch; }}
      .imggrid {{ grid-template-columns: repeat(auto-fill, minmax(120px, 1fr)); }}
      .card {{ padding: 10px; }}
    }}
    
    @media (max-width: 480px) {{
      body {{ padding: 8px; }}
      .imggrid {{ grid-template-columns: repeat(auto-fill, minmax(100px, 1fr)); }}
      .imgcard img {{ height: 100px; }}
    }}
    
    /* PWA Install Button */
    .install-btn {{ 
      background: linear-gradient(135deg, #4a90e2, #637dfc); 
      color: white; 
      border: none; 
      padding: 12px 20px; 
      border-radius: 10px; 
      font-weight: bold;
      display: none;
      cursor: pointer;
      box-shadow: 0 4px 12px rgba(74, 144, 226, 0.3);
    }}
    .install-btn:hover {{ transform: translateY(-2px); }}
    
    /* Loading Spinner */
    .loading {{ 
      display: inline-block; 
      width: 20px; 
      height: 20px; 
      border: 3px solid #f3f3f3; 
      border-top: 3px solid var(--accent); 
      border-radius: 50%; 
      animation: spin 1s linear infinite; 
    }}
    @keyframes spin {{ 0% {{ transform: rotate(0deg); }} 100% {{ transform: rotate(360deg); }} }}
    
    /* Offline Indicator */
    .offline-indicator {{ 
      position: fixed; 
      top: 10px; 
      right: 10px; 
      background: #ff4444; 
      color: white; 
      padding: 8px 12px; 
      border-radius: 8px; 
      font-size: 14px; 
      display: none; 
      z-index: 1000;
    }}
    
    /* Smooth Transitions */
    * {{ transition: background-color 0.3s ease, color 0.3s ease; }}
    
    /* Better Touch Targets */
    button, a, input, select {{ min-height: 44px; }}
  </style>
</head>
<body>
  <!-- Offline Indicator -->
  <div class="offline-indicator" id="offlineIndicator">ğŸ”„ ÙˆØ¶Ø¹ Ø¹Ø¯Ù… Ø§Ù„Ø§ØªØµØ§Ù„</div>
  
  <div class="toolbar">
    <h1 style="flex:1;">Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ â€” Ø¨Ø­Ø« / ØªÙ„Ø®ÙŠØµ / Ø£Ø³Ø¹Ø§Ø± / ØµÙˆØ± (Ù…Ø¬Ø§Ù†ÙŠ)</h1>
    <button class="install-btn" id="installBtn" onclick="installPWA()">ğŸ“± ØªØ«Ø¨ÙŠØª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚</button>
    <button onclick="toggleTheme()" title="Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù„ÙŠÙ„ÙŠ/Ø§Ù„Ù†Ù‡Ø§Ø±ÙŠ">ğŸŒ“ ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹</button>
  </div>

  <form method="post" class="row">
    <div class="col"><input type="text" name="question" placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø£Ùˆ Ø§Ø³Ù…/Ø·Ø±Ø§Ø² Ø§Ù„Ø³Ù„Ø¹Ø©..." required /></div>
    <div class="col">
      <select name="mode">
        <option value="smart">ğŸ¤– Ø¨Ø­Ø« Ø°ÙƒÙŠ (Ø¨Ø³Ø§Ù… AI)</option>
        <option value="summary">Ø¨Ø­Ø« & ØªÙ„Ø®ÙŠØµ</option>
        <option value="prices">Ø¨Ø­Ø« Ø£Ø³Ø¹Ø§Ø± (Ù…ØªØ§Ø¬Ø±)</option>
        <option value="images">Ø¨Ø­Ø« ØµÙˆØ±</option>
      </select>
    </div>
    <div class="col" style="max-width:140px;"><button type="submit">ØªÙ†ÙÙŠØ°</button></div>
  </form>

  {result_panel}

  <p class="note" style="margin-top:18px;">
    Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ğŸ‘/ğŸ‘ ÙŠØ­Ø³Ù‘Ù† ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØµØ§Ø¯Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§. Ø²Ø± Â«Ù†Ø³Ø® Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©Â» ÙŠÙ†Ø³Ø® Ø§Ù„Ù…Ù„Ø®Ù‘Øµ. Ø²Ø± Â«ØªØµØ¯ÙŠØ± PDFÂ» ÙŠÙ†Ø²Ù‘Ù„ Ù†Ø³Ø®Ø© Ù…Ø±ØªØ¨Ø© Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø©.
  </p>

<script>
// ÙˆØ¶Ø¹ Ù„ÙŠÙ„ÙŠ/Ù†Ù‡Ø§Ø±ÙŠ
(function(){{
  const saved = localStorage.getItem("theme");
  if(saved){{ document.documentElement.setAttribute("data-theme", saved); }}
}})();
function toggleTheme(){{
  const cur = document.documentElement.getAttribute("data-theme") || "light";
  const next = cur === "light" ? "dark" : "light";
  document.documentElement.setAttribute("data-theme", next);
  localStorage.setItem("theme", next);
}}

// Ù†Ø³Ø® Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
async function copyAnswer(text){{
  try{{
    await navigator.clipboard.writeText(text || "");
    alert("ØªÙ… Ù†Ø³Ø® Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©!");
  }}catch(e){{ alert("ØªØ¹Ø°Ù‘Ø± Ø§Ù„Ù†Ø³Ø®. Ø±Ø¨Ù…Ø§ Ø§Ù„Ù…ØªØµÙØ­ ÙŠÙ…Ù†Ø¹Ù‡."); }}
}}

// Ø·Ù„Ø¨ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø± (Ø¢Ù…Ù†)
function showMore(){{
  const form = document.querySelector('form');
  const button = event.target;
  
  // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ØµÙ„ÙŠ Ù…Ù† data-attribute Ø§Ù„Ø¢Ù…Ù†
  const questionField = document.querySelector('input[name="question"]');
  const originalQuestion = button.dataset.question;
  if (questionField && originalQuestion) {{
    questionField.value = originalQuestion;
  }}
  
  // Ø¥Ø¶Ø§ÙØ© ÙˆØ¶Ø¹ Ø§Ù„ØªÙØµÙŠÙ„
  const detailedField = document.createElement('input');
  detailedField.type = 'hidden';
  detailedField.name = 'detailed';
  detailedField.value = 'true';
  form.appendChild(detailedField);
  
  // Ø¥Ø¶Ø§ÙØ© ÙˆØ¶Ø¹ Ø°ÙƒÙŠ
  const modeField = document.querySelector('select[name="mode"]');
  if (modeField) {{
    modeField.value = 'smart';
  }}
  
  form.submit();
}}

// Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚ÙŠÙŠÙ…
async function sendFeedback(domain, delta){{
  try{{
    const fd = new FormData();
    fd.append("domain", domain);
    fd.append("delta", delta.toString());
    const r = await fetch("/feedback", {{method:"POST", body: fd}});
    if(r.ok){{ /* Ø§Ø®ØªÙŠØ§Ø±ÙŠ: Ø±Ø³Ø§Ù„Ø© */ }}
  }}catch(e){{ console.log(e); }}
}}

// PWA Functionality
let deferredPrompt;
let isOnline = navigator.onLine;

// ØªØ³Ø¬ÙŠÙ„ Service Worker
if ('serviceWorker' in navigator) {{
  window.addEventListener('load', async () => {{
    try {{
      const registration = await navigator.serviceWorker.register('/service-worker.js');
      console.log('âœ… Service Worker registered:', registration.scope);
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª
      registration.addEventListener('updatefound', () => {{
        const newWorker = registration.installing;
        newWorker.addEventListener('statechange', () => {{
          if (newWorker.state === 'installed' && navigator.serviceWorker.controller) {{
            showUpdateNotification();
          }}
        }});
      }});
      
    }} catch (error) {{
      console.error('âŒ Service Worker registration failed:', error);
    }}
  }});
}}

// Ù…Ø¹Ø§Ù„Ø¬Ø© ØªØ«Ø¨ÙŠØª PWA
window.addEventListener('beforeinstallprompt', (e) => {{
  e.preventDefault();
  deferredPrompt = e;
  document.getElementById('installBtn').style.display = 'block';
}});

// ØªØ«Ø¨ÙŠØª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
async function installPWA() {{
  if (!deferredPrompt) {{
    alert('Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø«Ø¨Øª Ø¨Ø§Ù„ÙØ¹Ù„ Ø£Ùˆ ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ«Ø¨ÙŠØª');
    return;
  }}
  
  const result = await deferredPrompt.prompt();
  console.log('PWA install result:', result);
  
  if (result.outcome === 'accepted') {{
    console.log('âœ… PWA ØªÙ… ØªØ«Ø¨ÙŠØªÙ‡');
    document.getElementById('installBtn').style.display = 'none';
  }}
  
  deferredPrompt = null;
}}

// Ù…Ø±Ø§Ù‚Ø¨Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„
function updateOnlineStatus() {{
  const indicator = document.getElementById('offlineIndicator');
  if (navigator.onLine) {{
    indicator.style.display = 'none';
    if (!isOnline) {{
      // Ø¹ÙˆØ¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„
      console.log('ğŸŒ Ø§Ù„Ø§ØªØµØ§Ù„ Ù…ØªÙˆÙØ± Ù…Ø±Ø© Ø£Ø®Ø±Ù‰');
    }}
    isOnline = true;
  }} else {{
    indicator.style.display = 'block';
    indicator.textContent = 'ğŸ“´ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª';
    isOnline = false;
  }}
}}

window.addEventListener('online', updateOnlineStatus);
window.addEventListener('offline', updateOnlineStatus);

// Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ«
function showUpdateNotification() {{
  const updateBanner = document.createElement('div');
  updateBanner.innerHTML = `
    <div style="position:fixed; top:0; left:0; right:0; background:#4a90e2; color:white; padding:12px; text-align:center; z-index:9999;">
      ğŸš€ ÙŠØªÙˆÙØ± ØªØ­Ø¯ÙŠØ« Ø¬Ø¯ÙŠØ¯ Ù„Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ
      <button onclick="location.reload()" style="margin-right:10px; padding:6px 12px; border:none; border-radius:4px; background:white; color:#4a90e2;">
        ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¢Ù†
      </button>
      <button onclick="this.parentElement.remove()" style="margin-right:5px; padding:6px 12px; border:none; border-radius:4px; background:rgba(255,255,255,0.2); color:white;">
        Ù„Ø§Ø­Ù‚Ø§Ù‹
      </button>
    </div>
  `;
  document.body.appendChild(updateBanner);
}}

// ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ - ØªØ£Ø¬ÙŠÙ„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±
if ('IntersectionObserver' in window) {{
  const imageObserver = new IntersectionObserver((entries) => {{
    entries.forEach(entry => {{
      if (entry.isIntersecting) {{
        const img = entry.target;
        if (img.dataset.src) {{
          img.src = img.dataset.src;
          img.removeAttribute('data-src');
          imageObserver.unobserve(img);
        }}
      }}
    }});
  }});
  
  // Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØµÙˆØ± Ø¹Ù†Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
  setTimeout(() => {{
    document.querySelectorAll('img[data-src]').forEach(img => {{
      imageObserver.observe(img);
    }});
  }}, 100);
}}

// ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø¹Ù†Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
document.addEventListener('DOMContentLoaded', () => {{
  updateOnlineStatus();
  
  // Ø¥Ø®ÙØ§Ø¡ Ø²Ø± Ø§Ù„ØªØ«Ø¨ÙŠØª Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø«Ø¨ØªØ§Ù‹
  if (window.matchMedia('(display-mode: standalone)').matches) {{
    document.getElementById('installBtn').style.display = 'none';
  }}
}});

console.log('ğŸ‰ Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ PWA Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!');
</script>
</body>
</html>
"""

def feedback_buttons(domain: str):
    d = html.escape(domain or "")
    return f'''
      <div class="fb">
        <button class="btn-mini" onclick="sendFeedback('{d}', 1)">ğŸ‘ Ù…ÙÙŠØ¯</button>
        <button class="btn-mini" onclick="sendFeedback('{d}', -1)">ğŸ‘ ØºÙŠØ± Ø¯Ù‚ÙŠÙ‚</button>
      </div>
    '''

def make_summary_card(title, url, summ, domain):
    return (
        f'<div class="card" style="margin-top:10px;"><strong>{html.escape(title)}</strong>'
        f'<div class="summary" style="margin-top:8px;">{html.escape(summ)}</div>'
        f'<div style="margin-top:8px;"><a target="_blank" href="{html.escape(url)}">ÙØªØ­ Ø§Ù„Ù…ØµØ¯Ø±</a></div>'
        f'{feedback_buttons(domain)}'
        f'</div>'
    )

def make_price_card(title, url, price, snippet, domain):
    price_html = f"<div><strong>Ø§Ù„Ø³Ø¹Ø±:</strong> {html.escape(price)}</div>" if price else "<div>Ø§Ù„Ø³Ø¹Ø± ØºÙŠØ± ÙˆØ§Ø¶Ø­ â€“ Ø§ÙØªØ­ Ø§Ù„Ù…ØµØ¯Ø± Ù„Ù„ØªØ­Ù‚Ù‚.</div>"
    sn = f'<div class="note" style="margin-top:6px;">{html.escape((snippet or "")[:180])}</div>' if snippet else ""
    return (
        f'<div class="card" style="margin-top:10px;"><strong>{html.escape(title)}</strong>'
        f'{price_html}'
        f'<div style="margin-top:8px;"><a target="_blank" href="{html.escape(url)}">ÙØªØ­ Ø§Ù„Ù…ØµØ¯Ø±</a></div>'
        f'{sn}'
        f'{feedback_buttons(domain)}'
        f'</div>'
    )

def make_toolbar_copy_pdf(q: str, mode: str, answer_text: str):
    pdf_url = "/export_pdf?" + urlencode({"q": q, "mode": mode})
    safe_answer_js = (answer_text or "").replace("\\", "\\\\").replace("'", "\\'").replace("\n", "\\n")
    return (
        f'<div class="row" style="margin-top:10px;">'
        f'  <div class="col" style="max-width:220px;"><button onclick="copyAnswer(\'{safe_answer_js}\'); return false;">ğŸ“‹ Ù†Ø³Ø® Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©</button></div>'
        f'  <div class="col" style="max-width:220px;"><a href="{pdf_url}" target="_blank"><button type="button">ğŸ–¨ï¸ ØªØµØ¯ÙŠØ± PDF</button></a></div>'
        f'</div>'
    )

# ---------------- Ø£ÙˆÙ„ÙˆÙŠØ© Ø°ÙƒÙŠØ© ----------------
def priority_key(item, mode="summary"):
    scores = get_scores()
    d = domain_of(item.get("href") or item.get("link") or item.get("url") or "")
    base = 2
    if d in PREFERRED_AR_DOMAINS: base -= 1
    if mode == "prices" and any(d.endswith(ms) or d==ms for ms in MARKET_SITES): base -= 0.5
    base -= 0.05 * scores.get(d, 0)
    return base

# ---------------- Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ----------------
@app.get("/", response_class=HTMLResponse)
async def form_get():
    return HTML_TEMPLATE.format(result_panel="")

@app.post("/", response_class=HTMLResponse)
async def form_post(question: str = Form(...), mode: str = Form("summary"), detailed: bool = Form(False)):
    q = (question or "").strip()
    if not q:
        return HTML_TEMPLATE.format(result_panel="")

    # ÙØ­Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
    if is_inappropriate_content(q):
        reminder_panel = get_reminder_message()
        return HTML_TEMPLATE.format(result_panel=reminder_panel)

    if mode == "prices":
        panel, answer_text = await handle_prices(q, return_plain=True)
    elif mode == "images":
        panel, answer_text = await handle_images(q)
    elif mode == "smart":
        panel, answer_text = await handle_summary(q, return_plain=True, smart_mode=True, detailed=detailed)
    else:
        panel, answer_text = await handle_summary(q, return_plain=True, smart_mode=False, detailed=detailed)

    # Ø´Ø±ÙŠØ· Ø£Ø¯ÙˆØ§Øª Ù†Ø³Ø® + PDF
    tools = make_toolbar_copy_pdf(q, mode, answer_text or "")
    return HTML_TEMPLATE.format(result_panel=tools + panel)

@app.post("/feedback")
async def feedback(domain: str = Form(...), delta: int = Form(...)):
    bump_score(domain, int(delta))
    return JSONResponse({"ok": True, "domain": domain, "score": get_scores().get(domain, 0)})

# PWA Routes
@app.get("/manifest.json")
async def get_manifest():
    """Ø®Ø¯Ù…Ø© Ù…Ù„Ù manifest.json Ù„Ù„Ù€ PWA"""
    try:
        with open("manifest.json", "r", encoding="utf-8") as f:
            manifest_content = f.read()
        return Response(content=manifest_content, media_type="application/json")
    except FileNotFoundError:
        return JSONResponse({"error": "Manifest not found"}, status_code=404)

@app.get("/service-worker.js")
async def get_service_worker():
    """Ø®Ø¯Ù…Ø© Ù…Ù„Ù service worker Ù„Ù„Ù€ PWA"""
    try:
        with open("service-worker.js", "r", encoding="utf-8") as f:
            sw_content = f.read()
        return Response(content=sw_content, media_type="application/javascript")
    except FileNotFoundError:
        return Response(content="console.log('Service Worker not found');", media_type="application/javascript")

# -------- ÙˆØ¶Ø¹: Ø¨Ø­Ø« & ØªÙ„Ø®ÙŠØµ Ø¹Ø±Ø¨ÙŠ --------
async def handle_summary(q: str, return_plain=False, smart_mode=False, detailed=False):
    cache_key = "sum:" + q
    cached = cache.get(cache_key)
    if cached and not return_plain:
        return cached, ""

    query_ar = q if "Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in q else (q + " Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    
    # Reduce search results to speed up response
    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(query_ar, region="xa-ar", safesearch="Strict", max_results=10)) or []
        if not results:
            with DDGS() as ddgs:
                results = list(ddgs.text(q, region="xa-ar", safesearch="Strict", max_results=10)) or []
    except Exception:
        results = []

    source_cards, combined_chunks = [], []
    successful_sources = 0
    
    for r in sorted(results, key=lambda it: priority_key(it, "summary")):
        if successful_sources >= 3:  # Limit to 3 sources for faster response
            break
            
        href = r.get("href") or r.get("link") or r.get("url")
        title = r.get("title") or ""
        snippet = r.get("body", "")[:200]  # Use snippet from search results
        
        if not href:
            continue
        d = domain_of(href)

        # Try cache first
        ckey = "url:" + href
        val = cache.get(ckey)
        page_text = ""
        
        if val and isinstance(val, (tuple, list)) and len(val) >= 2:
            page_text = val[0] if isinstance(val[0], str) else ""
        
        # If no cached content and not a problematic domain, try to fetch
        if not page_text and not any(domain in href for domain in ["16personalities", "reverso", "britannica"]):
            try:
                txt, raw = fetch_and_extract(href, timeout=2)  # Reduced timeout
                if txt and len(txt) > 100:
                    cache.set(ckey, (txt, raw), expire=60*60*24)
                    page_text = txt
            except Exception:
                pass  # Skip this source if fetch fails
        
        # If we have content, process it
        if page_text and isinstance(page_text, str) and len(page_text) > 50:
            if is_arabic(page_text, min_ar_chars=10):  # Reduced Arabic requirement
                summ = summarize_from_text(page_text, q, max_sentences=2)
                if summ:
                    combined_chunks.append(summ)
                    source_cards.append(make_summary_card(title, href, summ, d))
                    successful_sources += 1
        elif snippet:  # Use search snippet as fallback
            combined_chunks.append(snippet)
            source_cards.append(make_summary_card(title, href, snippet, d))
            successful_sources += 1

    if not combined_chunks:
        panel = '<div class="card" style="margin-top:12px;">Ù„Ù… Ø£Ø¹Ø«Ø± Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ ÙƒØ§ÙÙ. ØºÙŠÙ‘Ø± ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø£Ùˆ Ø£Ø¶Ù ÙƒÙ„Ù…Ø© "Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©".</div>'
        cache.set(cache_key, panel, expire=60*5)
        return (panel, "") if return_plain else (panel, None)

    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒÙŠ ÙÙŠ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø°ÙƒÙŠ
    if smart_mode and combined_chunks:
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒÙŠ
        search_results = []
        for r, chunk in zip(results[:len(combined_chunks)], combined_chunks):
            search_results.append({
                'title': r.get("title", ""),
                'content': chunk,
                'url': r.get("href", "")
            })
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒÙŠØ©
        question_analysis = smart_engine.analyze_question(q)
        smart_answer = smart_engine.generate_smart_answer(
            question_analysis, 
            search_results, 
            detailed or question_analysis.get('needs_detail', False)
        )
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ù…Ø¹ Ø£Ù…Ø§Ù† ÙƒØ§Ù…Ù„
        panel = (
            f'<div style="margin-top:18px;">'
            f'<h3>ğŸ¤– Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ:</h3><div class="card smart-answer">{html.escape(smart_answer)}</div>'
            f'<h3 style="margin-top:12px;">Ø§Ù„Ù…ØµØ§Ø¯Ø±:</h3>'
            f'{"".join(source_cards)}'
            f'<div style="margin-top:12px;">'
            f'<button onclick="showMore()" data-question="{html.escape(q, quote=True)}" class="btn-detail">ğŸ“– Ø£Ø±ÙŠØ¯ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø±</button>'
            f'</div>'
            f'</div>'
        )
        cache.set(cache_key + "_smart", panel, expire=60*60)
        return (panel, smart_answer) if return_plain else (panel, None)
    
    # Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ø¯ÙŠ
    final_answer = " ".join(combined_chunks)
    panel = (
        f'<div style="margin-top:18px;">'
        f'<h3>Ø³Ø¤Ø§Ù„Ùƒ:</h3><div class="card">{html.escape(q)}</div>'
        f'<h3 style="margin-top:12px;">Ø§Ù„Ù…Ù„Ø®Ù‘Øµ (Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±):</h3><div class="summary">{html.escape(final_answer)}</div>'
        f'<h3 style="margin-top:12px;">Ø§Ù„Ù…ØµØ§Ø¯Ø±:</h3>'
        f'{"".join(source_cards)}'
        f'</div>'
    )
    cache.set(cache_key, panel, expire=60*60)
    return (panel, final_answer) if return_plain else (panel, None)

# -------- ÙˆØ¶Ø¹: Ø¨Ø­Ø« Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…ØªØ§Ø¬Ø± --------
async def handle_prices(q: str, return_plain=False):
    cache_key = "price:" + q
    cached = cache.get(cache_key)
    if cached and not return_plain:
        return cached, ""

    sites_filter = " OR ".join([f"site:{s}" for s in MARKET_SITES])
    query = f'{q} {sites_filter}'
    with DDGS() as ddgs:
        results = list(ddgs.text(query, region="xa-ar", safesearch="Off", max_results=30)) or []
    if not results:
        with DDGS() as ddgs:
            results = list(ddgs.text(q + " " + sites_filter, region="wt-wt", safesearch="Off", max_results=30)) or []

    cards, seen = [], set()
    lines_for_pdf = []
    for r in sorted(results, key=lambda it: priority_key(it, "prices")):
        url = r.get("href") or r.get("link") or r.get("url")
        title = r.get("title") or ""
        snippet = r.get("body") or ""
        if not url or url in seen:
            continue
        seen.add(url)
        d = domain_of(url)

        price = ""
        try:
            ckey = "purl:" + url
            html_page = cache.get(ckey)
            if html_page is None:
                html_page = fetch(url, timeout=3)
                if html_page and len(html_page) < 1_500_000:
                    cache.set(ckey, html_page, expire=60*60*6)
            price = extract_price_from_html(html_page or "")
            if not price and d.endswith("aliexpress.com"):
                soup = BeautifulSoup(html_page or "", "html.parser")
                meta_price = soup.find(attrs={"itemprop": "price"})
                if meta_price:
                    price = (meta_price.get("content") or meta_price.text or "").strip()
        except Exception:
            price = ""

        cards.append(make_price_card(title, url, price, snippet, d))
        lines_for_pdf.append(f"- {title} | {price or 'â€”'} | {url}")
        if len(cards) >= 10:
            break

    if not cards:
        panel = '<div class="card" style="margin-top:12px;">Ù„Ù… Ø£Ø¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙŠ Ø§Ù„Ù…ØªØ§Ø¬Ø±. Ø¬Ø±Ù‘Ø¨ Ø§Ø³Ù…Ù‹Ø§ Ø£Ø¯Ù‚ Ù„Ù„Ù…Ù†ØªØ¬ (Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„/Ø§Ù„Ø·Ø±Ø§Ø²) Ø£Ùˆ Ø£Ø¶Ù site:aliexpress.com.</div>'
        cache.set(cache_key, panel, expire=60*5)
        return (panel, "") if return_plain else (panel, None)

    # Ù†Øµ Ø¨Ø³ÙŠØ· Ù„Ù„ØªØµØ¯ÙŠØ±/Ø§Ù„Ù†Ø³Ø®
    answer_text = "Ù†ØªØ§Ø¦Ø¬ Ø£Ø³Ø¹Ø§Ø±:\n" + "\n".join(lines_for_pdf)
    panel = f'<div style="margin-top:18px;"><h3>Ø¨Ø­Ø« Ø£Ø³Ø¹Ø§Ø± Ø¹Ù†: {html.escape(q)}</h3>{"".join(cards)}</div>'
    cache.set(cache_key, panel, expire=60*30)
    return (panel, answer_text) if return_plain else (panel, None)

# -------- ÙˆØ¶Ø¹: Ø¨Ø­Ø« Ø§Ù„ØµÙˆØ± --------
async def handle_images(q: str):
    key = "img:" + q
    cached = cache.get(key)
    if cached:
        return cached, ""

    items = []
    try:
        if DDGS:
            with DDGS() as dd:
                for it in dd.images(keywords=q, region="xa-ar", safesearch="Off", max_results=20):
                    items.append({"title": it.get("title") or "", "image": it.get("image"), "source": it.get("url")})
        else:
            # Ø§Ø­ØªÙŠØ§Ø·: Ø§Ø³ØªØ®Ø¯Ù… Ø¨Ø­Ø« ÙˆÙŠØ¨ Ø¹Ø§Ø¯ÙŠ Ù…Ø¹ "ØµÙˆØ±"
            with DDGS() as ddgs:
                results = list(ddgs.text(q + " ØµÙˆØ±", region="xa-ar", safesearch="Off", max_results=20)) or []
            for r in results:
                items.append({"title": r.get("title") or "", "image": None, "source": r.get("href") or r.get("url")})
    except Exception:
        items = []

    if not items:
        panel = '<div class="card" style="margin-top:12px;">Ù„Ù… Ø£Ø¬Ø¯ ØµÙˆØ±Ù‹Ø§ Ù…Ù†Ø§Ø³Ø¨Ø©. Ø­Ø§ÙˆÙ„ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø± Ø£Ùˆ ÙƒÙ„Ù…Ø© "ØµÙˆØ±".</div>'
        cache.set(key, (panel, ""), expire=60*10)
        return panel, ""

    cards = []
    for it in items[:16]:
        img = it.get("image")
        src = it.get("source")
        title = it.get("title") or ""
        if img:
            cards.append(f'<div class="imgcard"><a href="{html.escape(src or img)}" target="_blank"><img src="{html.escape(img)}" alt=""/></a></div>')
        else:
            # Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØµÙˆØ±Ø© Ù…Ø¨Ø§Ø´Ø±Ø©â€”Ù†Ø¹Ø±Ø¶ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø±
            cards.append(f'<div class="card"><a href="{html.escape(src)}" target="_blank">{html.escape(title or "ÙØªØ­ Ø§Ù„Ù…ØµØ¯Ø±")}</a></div>')

    panel = f'<div style="margin-top:18px;"><h3>Ù†ØªØ§Ø¦Ø¬ ØµÙˆØ± Ø¹Ù†: {html.escape(q)}</h3><div class="imggrid">{"".join(cards)}</div></div>'
    cache.set(key, (panel, ""), expire=60*20)
    return panel, ""

# -------- ØªØµØ¯ÙŠØ± PDF --------
@app.get("/export_pdf")
def export_pdf(q: str, mode: str = "summary"):
    """
    ÙŠØ¨Ù†ÙŠ PDF Ø¨Ø³ÙŠØ· Ù…Ù† Ø¢Ø®Ø± Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„ÙƒØ§Ø´ (Ø­Ø³Ø¨ q + mode).
    - Ù„Ù„Ù…Ù„Ø®Øµ: ÙŠØ³ØªØ®Ø±Ø¬ Ù†Øµ Ø§Ù„Ù…Ù„Ø®Øµ ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø± Ù…Ù† Ø§Ù„Ù€ panel Ø§Ù„Ù…Ø®Ø²Ù†.
    - Ù„Ù„Ø£Ø³Ø¹Ø§Ø±: ÙŠØ³Ø±Ø¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†/Ø§Ù„Ø£Ø³Ø¹Ø§Ø±/Ø§Ù„Ø±ÙˆØ§Ø¨Ø·.
    """
    if mode == "prices":
        panel, ans = handle_prices_sync(q)
        text_for_pdf = ans or "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª."
        title = f"Ø¨Ø­Ø« Ø£Ø³Ø¹Ø§Ø±: {q}"
    elif mode == "images":
        panel = cache.get("img:" + q)
        title = f"Ù†ØªØ§Ø¦Ø¬ ØµÙˆØ±: {q}"
        text_for_pdf = f"Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù†Ø§ØµØ±: {len(panel[0]) if panel else 0}\n(ÙŠÙÙ†ØµØ­ Ø¨ÙØªØ­ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ù…ØªØµÙØ­ Ù„Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„ØµÙˆØ±)"
    else:
        panel_html = cache.get("sum:" + q)
        if not panel_html:
            # Ø­Ø§ÙˆÙ„ ØªÙˆÙ„ÙŠØ¯ Ø³Ø±ÙŠØ¹ Ø«Ù… Ø§Ø³ØªØ®Ø¯Ù…Ù‡
            p, ans = app.run_sync(handle_summary(q, return_plain=True))  # Ù‚Ø¯ Ù„Ø§ ÙŠØ¹Ù…Ù„ ÙÙŠ Ø¨Ø¹Ø¶ Ø¨ÙŠØ¦Ø§Øª ASGIØŒ Ù„Ø°Ø§ Ù†Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ§Ø´ ÙÙŠ Ø§Ù„Ø¹Ø§Ø¯Ø©
            panel_html = p
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„Ø®Øµ ÙƒÙ†Øµ Ù…Ù† Ø§Ù„Ù€ HTML
        soup = BeautifulSoup(panel_html or "", "html.parser")
        summary_div = soup.find("div", {"class": "summary"})
        text_for_pdf = summary_div.get_text(" ", strip=True) if summary_div else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª."
        title = f"Ù…Ù„Ø®Øµ Ø§Ù„Ø¨Ø­Ø«: {q}"

    pdf = FPDF()
    pdf.add_page()
    pdf.add_font('Arial', '', fname='')
    pdf.set_font("Arial", size=14)
    pdf.multi_cell(0, 10, title)
    pdf.ln(4)
    pdf.set_font("Arial", size=12)
    for line in (text_for_pdf or "").split("\n"):
        pdf.multi_cell(0, 8, line)

    pdf_bytes = pdf.output(dest="S").encode("latin1", "ignore")
    headers = {
        "Content-Disposition": f'attachment; filename="bassam_ai_{mode}.pdf"',
        "Content-Type": "application/pdf",
    }
    return Response(content=pdf_bytes, headers=headers)

# Ù†Ø³Ø®Ø© Ù…ØªØ²Ø§Ù…Ù†Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø³Ø¹Ø±ÙŠ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ PDF Ù„Ùˆ Ø§Ø­ØªØ¬Ù†Ø§
def handle_prices_sync(q: str):
    sites_filter = " OR ".join([f"site:{s}" for s in MARKET_SITES])
    query = f'{q} {sites_filter}'
    with DDGS() as ddgs:
        results = list(ddgs.text(query, region="xa-ar", safesearch="Off", max_results=15)) or []
    if not results:
        with DDGS() as ddgs:
            results = list(ddgs.text(q + " " + sites_filter, region="wt-wt", safesearch="Off", max_results=15)) or []
    lines = []
    for r in results[:10]:
        url = r.get("href") or r.get("link") or r.get("url")
        title = r.get("title") or ""
        price = ""
        try:
            h = fetch(url, timeout=3)
            price = extract_price_from_html(h)
        except Exception:
            pass
        lines.append(f"- {title} | {price or 'â€”'} | {url}")
    panel = ""  # ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù… Ù‡Ù†Ø§
    return panel, "Ù†ØªØ§Ø¦Ø¬ Ø£Ø³Ø¹Ø§Ø±:\n" + "\n".join(lines)

@app.get("/health")
def health():
    return {"ok": True}

# Ø¥Ø¶Ø§ÙØ© endpoint Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø·Ù„Ø¨Ø§Øª /api Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø©
@app.head("/api")
@app.get("/api") 
async def api_endpoint():
    return {"status": "active", "message": "Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ API Ø¬Ø§Ù‡Ø²"}