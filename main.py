# main.py â€” Bassam Ø§Ù„Ø°ÙƒÙŠ v3.6 (Chat + RAG + Web + Math + PDF/Image Upload)
from fastapi import FastAPI, Request, Query, Body, UploadFile, File, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware

import os, json, time, re, shutil
from typing import List, Dict, Any

# === Ù†ØµÙŠ ÙˆØªÙ„Ø®ÙŠØµ ===
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS
from readability import Document

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¢Ù…Ù† Ù„Ù€ sumy (PlaintextParser Ù‚Ø¯ ØªØ¸Ù‡Ø± Ø¨ØµÙŠØºØªÙŠÙ†)
try:
    from sumy.parsers.text import PlaintextParser
except Exception:
    from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer

# === Ø±ÙŠØ§Ø¶ÙŠØ§Øª ===
from sympy import symbols, sympify, diff, integrate, simplify, sin, cos, tan, log, exp

# === ÙÙ‡Ø±Ø³Ø© RAG Ù…Ø­Ù„ÙŠØ© (BM25) ===
from rank_bm25 import BM25Okapi

# === PDF & Images ===
from pypdf import PdfReader
from PIL import Image  # ÙÙ‚Ø· Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ù‚Ø¨ÙˆÙ„ Ø§Ù„ØµÙˆØ±

# -------------------------
# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# -------------------------
DATA_DIR   = "data"
NOTES_DIR  = os.path.join(DATA_DIR, "notes")
FILES_DIR  = "files"                # Ù…Ù„ÙØ§Øª Ù…Ø±ÙÙˆØ¹Ø© (PDF/ØµÙˆØ±) ØªÙØ®Ø¯Ù… Ø¹Ø¨Ø± /files/...
UPLOADS_DIR = os.path.join(FILES_DIR, "uploads")

LEARN_PATH = os.path.join(NOTES_DIR, "learned.jsonl")
USAGE_PATH = os.path.join(DATA_DIR,  "usage_stats.json")

app = FastAPI(title="Bassam Ø§Ù„Ø°ÙƒÙŠ ğŸ¤–", version="3.6")

# Ø±Ø¨Ø· Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ø³ØªØ§ØªÙŠÙƒÙŠØ©
os.makedirs(FILES_DIR, exist_ok=True)
os.makedirs(UPLOADS_DIR, exist_ok=True)
app.mount("/files", StaticFiles(directory=FILES_DIR), name="files")

try:
    app.mount("/static", StaticFiles(directory="static"), name="static")
    templates = Jinja2Templates(directory="templates")
except Exception:
    templates = None

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

# -------------------------
# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# -------------------------
def _ensure_dirs():
    os.makedirs(DATA_DIR,   exist_ok=True)
    os.makedirs(NOTES_DIR,  exist_ok=True)
    if not os.path.exists(LEARN_PATH):
        open(LEARN_PATH, "a", encoding="utf-8").close()
    if not os.path.exists(USAGE_PATH):
        with open(USAGE_PATH, "w", encoding="utf-8") as f:
            json.dump({"requests": 0, "last_time": int(time.time())}, f)

_ensure_dirs()

def _read_md_txt_files() -> List[Dict[str, str]]:
    docs = []
    # .md/.txt Ù…Ù† data/
    for root, _, files in os.walk(DATA_DIR):
        for fn in files:
            if fn.endswith(".md") or fn.endswith(".txt"):
                path = os.path.join(root, fn)
                try:
                    with open(path, "r", encoding="utf-8", errors="ignore") as f:
                        docs.append({"file": path, "text": f.read()})
                except:
                    pass
    # Ø¨Ù†Ùƒ Ø§Ù„ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ø°Ø§ØªÙŠ
    try:
        with open(LEARN_PATH, "r", encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue
                obj = json.loads(line)
                text = f"Ø³: {obj.get('question','')}\nØ¬: {obj.get('answer','')}\nÙˆØ³ÙˆÙ…:{','.join(obj.get('tags',[]))}"
                docs.append({"file": "learned", "text": text})
    except:
        pass
    return docs

def _tokenize_ar(s: str) -> List[str]:
    # ØªÙ‚Ø·ÙŠØ¹ Ø¨Ø³ÙŠØ· ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
    return re.findall(r"[\w\u0600-\u06FF]+", s.lower())

BM25_INDEX = None
BM25_CORPUS = []
BM25_DOCS: List[Dict[str, str]] = []

def build_index():
    """Ø£Ø¹Ø¯ Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ RAG Ù…Ù† Ù…Ù„ÙØ§Øª data/ ÙˆÙ…Ù† Ø¨Ù†Ùƒ Ø§Ù„ØªØ¹Ù„Ù…."""
    global BM25_INDEX, BM25_CORPUS, BM25_DOCS
    BM25_DOCS = _read_md_txt_files()
    BM25_CORPUS = [_tokenize_ar(d["text"]) for d in BM25_DOCS]
    BM25_INDEX = BM25Okapi(BM25_CORPUS) if BM25_CORPUS else None
    return len(BM25_DOCS)

build_index()

# -------------------------
# ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø°ÙƒØ§Ø¡
# -------------------------
def summarize_text(text: str, max_sentences: int = 3) -> str:
    try:
        parser = PlaintextParser.from_string(text, Tokenizer("arabic"))
        summarizer = TextRankSummarizer()
        sents = summarizer(parser.document, max_sentences)
        return " ".join(str(s) for s in sents) if sents else text[:400]
    except Exception:
        return text[:400]

def web_search(query: str):
    try:
        with DDGS() as ddgs:
            res = ddgs.text(query, region="xa-ar", max_results=5)
            return [{"title": r["title"], "link": r["href"], "snippet": r["body"]} for r in res]
    except Exception:
        return []

def rag_bm25(query: str, k: int = 3):
    if not BM25_INDEX:
        return []
    toks = _tokenize_ar(query)
    scores = BM25_INDEX.get_scores(toks)
    pairs = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:k]
    results = []
    for idx, sc in pairs:
        if sc < 1.0:
            continue
        doc = BM25_DOCS[idx]
        snippet = doc["text"][:800]
        results.append({"file": doc["file"], "score": float(sc), "snippet": snippet})
    return results

def solve_math(expr: str):
    try:
        x = symbols('x')
        parsed = sympify(expr)
        return {
            "input": str(parsed),
            "simplified": str(simplify(parsed)),
            "derivative": str(diff(parsed, x)),
            "integral": str(integrate(parsed, x)),
        }
    except Exception as e:
        return {"error": f"ØªØ¹Ø°Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©: {e}"}

def log_usage():
    try:
        with open(USAGE_PATH, "r+", encoding="utf-8") as f:
            data = json.load(f)
            data["requests"] = int(data.get("requests", 0)) + 1
            data["last_time"] = int(time.time())
            f.seek(0); json.dump(data, f); f.truncate()
    except Exception:
        pass

def save_feedback(question: str, answer: str, tags: List[str]):
    record = {
        "time": int(time.time()),
        "question": question.strip(),
        "answer": answer.strip(),
        "tags": tags or []
    }
    with open(LEARN_PATH, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")

# -------------------------
# Ø£Ø¯ÙˆØ§Øª PDF/ØµÙˆØ±Ø©
# -------------------------
def extract_pdf_text(pdf_path: str) -> str:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ù…Ù† PDF (Ø£ÙØ¶Ù„ Ù…Ø§ ÙŠÙ…ÙƒÙ†)."""
    try:
        reader = PdfReader(pdf_path)
        chunks = []
        for page in reader.pages:
            chunks.append(page.extract_text() or "")
        return "\n".join(chunks)
    except Exception as e:
        return ""

def ensure_safe_filename(name: str) -> str:
    # Ø§Ø³Ù… Ù…Ù„Ù Ø¨Ø³ÙŠØ· ÙˆØ¢Ù…Ù†
    name = re.sub(r"[^\w\-.]+", "_", name)
    return name[:120] or f"file_{int(time.time())}"

# -------------------------
# ÙˆØ§Ø¬Ù‡Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# -------------------------
@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    if templates:
        return templates.TemplateResponse("index.html", {"request": request, "version": "v3.6"})
    # Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¨Ø³ÙŠØ·Ø© Ø¥Ù† Ù„Ù… ØªÙˆØ¬Ø¯ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨
    html = """<!doctype html><meta charset='utf-8'><title>Bassam v3.6</title>
    <div style='font-family:system-ui;padding:20px;color:#e7ecff;background:#0b1020'>
      <h2>ğŸ¤– Ø¨Ø³Ù‘Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ v3.6</h2>
      <p>Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ø§Ø±ÙØ¹ <code>templates/index.html</code>.</p>
    </div>"""
    return HTMLResponse(html)

@app.get("/healthz")
def healthz():
    return {"status": "ok", "version": "3.6", "docs_indexed": len(BM25_DOCS)}

@app.get("/ask")
def ask(q: str = Query(..., description="Ø³Ø¤Ø§Ù„Ùƒ")):
    log_usage()
    q = (q or "").strip()
    if not q:
        return {"error": "Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ùƒ"}

    # ØªÙ„Ù…ÙŠØ­ Ø¨Ø³ÙŠØ· Ù„Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©/Ø§Ù„Ø§Ø®ØªØµØ§Ø±Ø§Øª: (Ù…ÙƒØ§Ù† Ø³Ø±ÙŠØ¹ Ù„Ù„ØªÙˆØ³Ø¹Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§)
    # Ù‡Ù†Ø§ Ù†ÙƒØªÙÙŠ Ø¨Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±.

    # Ø±ÙŠØ§Ø¶ÙŠØ§ØªØŸ
    if any(tok in q for tok in ["sin", "cos", "tan", "log", "exp", "^"]) or ("Ù…Ø´ØªÙ‚Ø©" in q) or ("ØªÙƒØ§Ù…Ù„" in q):
        return {"type": "math", "result": solve_math(q)}

    # RAG Ù…Ø­Ù„ÙŠ
    rag = rag_bm25(q, k=3)
    if rag:
        s = summarize_text(rag[0]["snippet"], 3)
        return {"type": "rag", "hits": rag, "summary": s}

    # Ø¨Ø­Ø« ÙˆÙŠØ¨
    web = web_search(q)
    if web:
        for item in web:
            item["summary"] = summarize_text(item["snippet"], 2)
        return {"type": "web", "results": web}

    return {"msg": "Ù„Ù… Ø£Ø¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ø­ÙˆÙ„ Ø³Ø¤Ø§Ù„Ùƒ."}

# === Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø°Ø§ØªÙŠ Ø¹Ø¨Ø± ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© ===
@app.post("/feedback")
def feedback(payload: Dict[str, Any] = Body(...)):
    q = (payload.get("question") or "").strip()
    a = (payload.get("answer") or "").strip()
    tags = payload.get("tags") or []
    if not q or not a:
        return {"ok": False, "error": "question Ùˆ answer Ù…Ø·Ù„ÙˆØ¨Ø©"}
    save_feedback(q, a, tags)
    n = build_index()
    return {"ok": True, "indexed_docs": n}

# Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³ ÙŠØ¯ÙˆÙŠÙ‹Ø§
@app.post("/train")
def train():
    n = build_index()
    return {"ok": True, "indexed_docs": n}

# Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø¨Ø³ÙŠØ·Ø©
@app.get("/stats")
def stats():
    try:
        with open(USAGE_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {"requests": 0}

# -------------------------
# Ø±ÙØ¹ PDF
# -------------------------
@app.post("/upload/pdf")
async def upload_pdf(file: UploadFile = File(...)):
    if not file.filename.lower().endswith(".pdf"):
        raise HTTPException(400, "Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF ÙÙ‚Ø·.")
    safe = ensure_safe_filename(file.filename)
    dest_path = os.path.join(UPLOADS_DIR, safe)
    # Ø§Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
    with open(dest_path, "wb") as out:
        shutil.copyfileobj(file.file, out)
    # Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Øµ ÙˆØ§Ø­ÙØ¸Ù‡ ÙÙŠ data/ ÙƒÙŠ ÙŠØ¯Ø®Ù„ Ø¶Ù…Ù† RAG
    text = extract_pdf_text(dest_path)
    if text.strip():
        txt_name = safe.rsplit(".", 1)[0] + ".txt"
        txt_path = os.path.join(DATA_DIR, txt_name)
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write(text)
        n = build_index()
    else:
        n = len(BM25_DOCS)

    # Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¹Ø§Ù…
    file_url = f"/files/uploads/{safe}"
    return {"ok": True, "file_url": file_url, "indexed_docs": n}

# -------------------------
# Ø±ÙØ¹ ØµÙˆØ±Ø© + Ø±ÙˆØ§Ø¨Ø· Ø¨Ø­Ø« Ø¹ÙƒØ³ÙŠ
# -------------------------
@app.post("/upload/image")
async def upload_image(file: UploadFile = File(...)):
    ext = os.path.splitext(file.filename)[1].lower()
    if ext not in [".jpg", ".jpeg", ".png", ".webp", ".bmp"]:
        raise HTTPException(400, "Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ø¨ØµÙŠØºØ© jpg/png/webp/bmp.")
    safe = ensure_safe_filename(file.filename or f"img_{int(time.time())}{ext}")
    dest_path = os.path.join(UPLOADS_DIR, safe)
    with open(dest_path, "wb") as out:
        shutil.copyfileobj(file.file, out)
    # ØªØ­Ù‚Ù‚ Ø³Ø±ÙŠØ¹ Ø£Ù†Ù‡Ø§ ØµÙˆØ±Ø© Ø¨Ø§Ù„ÙØ¹Ù„
    try:
        Image.open(dest_path).verify()
    except Exception:
        os.remove(dest_path)
        raise HTTPException(400, "Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ ØµÙˆØ±Ø© ØµØ§Ù„Ø­Ø©.")

    public_url = f"/files/uploads/{safe}"
    # Ø±ÙˆØ§Ø¨Ø· Ø¨Ø­Ø« Ø¹ÙƒØ³ÙŠ Ø´Ù‡ÙŠØ±Ø© (ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ URL Ø¹Ø§Ù… Ù„Ù„ØµÙˆØ±Ø©)
    # Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù†ØµÙ‘Ø§Øª Ù‚Ø¯ ØªØ¹ÙŠØ¯ ØªÙˆØ¬ÙŠÙ‡/ØªØ­Ø¬Ø¨ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ØŒ Ù„ÙƒÙ† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ù‹Ø§
    google = f"https://www.google.com/searchbyimage?image_url={{BASE}}".replace("{BASE}", public_url)
    bing   = f"https://www.bing.com/images/search?q=imgurl:{{BASE}}&view=detailv2&iss=sbi".replace("{BASE}", public_url)
    yandex = f"https://yandex.com/images/search?rpt=imageview&url={{BASE}}".replace("{BASE}", public_url)
    tineye = f"https://tineye.com/search?url={{BASE}}".replace("{BASE}", public_url)

    return {"ok": True, "image_url": public_url,
            "reverse": {"google": google, "bing": bing, "yandex": yandex, "tineye": tineye}}

# ÙÙ‡Ø±Ø³ Ø¨Ø³ÙŠØ· Ù„Ù„Ù…Ù„ÙØ§Øª
@app.get("/files_list")
def files_list():
    items = []
    for root, _, files in os.walk(FILES_DIR):
        for fn in files:
            rel = os.path.relpath(os.path.join(root, fn), FILES_DIR).replace("\\", "/")
            items.append("/files/" + rel)
    items.sort()
    return {"count": len(items), "files": items}

# Ù†Ù‚Ø·Ø© ØªØ´ØºÙŠÙ„ Ù…Ø­Ù„ÙŠØ©
if __name__ == "__main__":
    import uvicorn, os
    uvicorn.run("main:app", host="0.0.0.0", port=int(os.environ.get("PORT", 8000)))
