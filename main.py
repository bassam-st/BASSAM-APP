# main.py â€” Ø¨Ø­Ø« Ø¹Ø±Ø¨ÙŠ Ù…Ø¬Ø§Ù†ÙŠ + ØªÙ„Ø®ÙŠØµ Ø°ÙƒÙŠ + Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…ØªØ§Ø¬Ø± + ØµÙˆØ± + ØªÙ‚ÙŠÙŠÙ… + PDF + Ù†Ø³Ø® + ÙˆØ¶Ø¹ Ù„ÙŠÙ„ÙŠ
from fastapi import FastAPI, Form, Request, Response
from fastapi.responses import HTMLResponse, JSONResponse
from ddgs import DDGS
from readability import Document
from bs4 import BeautifulSoup
from diskcache import Cache
from urllib.parse import urlparse, urlencode
from fpdf import FPDF
import requests, re, html, time

app = FastAPI()
cache = Cache(".cache")

# ---------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ----------------
PREFERRED_AR_DOMAINS = {
    "ar.wikipedia.org", "ar.m.wikipedia.org",
    "mawdoo3.com", "almrsal.com", "sasapost.com",
    "arabic.cnn.com", "bbcarabic.com", "aljazeera.net",
    "ar.wikihow.com", "moe.gov.sa", "yemen.gov.ye", "moh.gov.sa"
}

MARKET_SITES = [
    "alibaba.com", "1688.com", "aliexpress.com",
    "amazon.com", "amazon.ae", "amazon.sa", "amazon.eg",
    "noon.com", "jumia.com", "jumia.com.eg",
    "ebay.com", "made-in-china.com", "temu.com", "souq.com"
]

HDRS = {"User-Agent": "Mozilla/5.0 (compatible; BassamBot/1.2)"}

# -------- Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù„ØºØ© ÙˆØ§Ù„Ù…Ù„Ø®Øµ --------
AR_RE = re.compile(r"[Ø§Ø£Ø¥Ø¢Ø¡-ÙŠ]")
def is_arabic(text: str, min_ar_chars: int = 30) -> bool:
    return len(AR_RE.findall(text or "")) >= min_ar_chars

# -------- Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© --------
class SmartAnswerEngine:
    def __init__(self):
        self.question_types = {
            'Ù…Ø§ Ù‡Ùˆ': 'definition',
            'Ù…Ø§ Ù‡ÙŠ': 'definition', 
            'ÙƒÙŠÙ': 'how_to',
            'Ù„Ù…Ø§Ø°Ø§': 'why',
            'Ù…ØªÙ‰': 'when',
            'Ø£ÙŠÙ†': 'where',
            'Ù…Ù†': 'who',
            'ÙƒÙ…': 'quantity',
            'Ù‡Ù„': 'yes_no'
        }
        
    def analyze_question(self, question: str):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„ÙÙ‡Ù… Ù†ÙˆØ¹Ù‡ ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        question_lower = question.strip().lower()
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
        question_type = 'general'
        for keyword, qtype in self.question_types.items():
            if question_lower.startswith(keyword):
                question_type = qtype
                break
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        keywords = self.extract_keywords(question)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ­ØªØ§Ø¬ ØªÙØµÙŠÙ„
        needs_detail = any(word in question_lower for word in ['Ø§Ø´Ø±Ø­', 'ÙØµÙ„', 'ÙˆØ¶Ø­', 'Ø¨Ø§Ù„ØªÙØµÙŠÙ„'])
        
        return {
            'type': question_type,
            'keywords': keywords,
            'needs_detail': needs_detail,
            'original': question
        }
    
    def extract_keywords(self, text: str):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ"""
        # Ø¥Ø²Ø§Ù„Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… ÙˆØ­Ø±ÙˆÙ Ø§Ù„Ø¬Ø±
        stop_words = {'Ù…Ø§', 'Ù‡Ùˆ', 'Ù‡ÙŠ', 'ÙƒÙŠÙ', 'Ù„Ù…Ø§Ø°Ø§', 'Ù…ØªÙ‰', 'Ø£ÙŠÙ†', 'Ù…Ù†', 'ÙƒÙ…', 'Ù‡Ù„', 
                     'ÙÙŠ', 'Ø¹Ù„Ù‰', 'Ø¥Ù„Ù‰', 'Ù…Ù†', 'Ø¹Ù†', 'Ù…Ø¹', 'Ø¶Ø¯', 'ØªØ­Øª', 'ÙÙˆÙ‚'}
        
        words = text.split()
        keywords = [word.strip('ØŸØŒ.!') for word in words if word not in stop_words and len(word) > 2]
        return keywords[:5]  # Ø£Ù‡Ù… 5 ÙƒÙ„Ù…Ø§Øª
        
    def generate_smart_answer(self, question_analysis, search_results, detailed=False):
        """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ø°ÙƒÙŠØ© Ù…Ø®ØªØµØ±Ø© Ù…Ù† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«"""
        if not search_results:
            return "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø³Ø¤Ø§Ù„Ùƒ. Ø­Ø§ÙˆÙ„ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„."
            
        # Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±
        all_content = []
        sources = []
        
        for result in search_results:
            if result.get('content'):
                all_content.append(result['content'])
                sources.append(result.get('title', 'Ù…ØµØ¯Ø±'))
        
        if not all_content:
            return "Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ."
        
        # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø©
        answer = self.create_targeted_answer(question_analysis, all_content, detailed)
        
        # Ø¥Ø¶Ø§ÙØ© Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
        if len(sources) > 0:
            source_list = ", ".join(sources[:3])  # Ø£ÙˆÙ„ 3 Ù…ØµØ§Ø¯Ø±
            answer += f"\n\nØ§Ù„Ù…ØµØ§Ø¯Ø±: {source_list}"
            
        return answer
    
    def create_targeted_answer(self, analysis, content_list, detailed):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø³ØªÙ‡Ø¯ÙØ© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„"""
        combined_content = " ".join(content_list)
        question_type = analysis['type']
        
        if question_type == 'definition':
            return self.answer_definition(combined_content, detailed)
        elif question_type == 'how_to':
            return self.answer_how_to(combined_content, detailed)
        elif question_type == 'why':
            return self.answer_why(combined_content, detailed)
        elif question_type == 'when':
            return self.answer_when(combined_content, detailed)
        elif question_type == 'where':
            return self.answer_where(combined_content, detailed)
        elif question_type == 'who':
            return self.answer_who(combined_content, detailed)
        else:
            return self.answer_general(combined_content, detailed)
    
    def answer_definition(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ¹Ø±ÙŠÙ (Ù…Ø§ Ù‡Ùˆ/Ù…Ø§ Ù‡ÙŠ)"""
        sentences = self.split_into_sentences(content)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…Ù„ Ø§Ù„ØªØ¹Ø±ÙŠÙ
        definition_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['Ù‡Ùˆ', 'Ù‡ÙŠ', 'ÙŠØ¹Ø±Ù', 'ÙŠÙØ¹Ø±Ù‘Ù', 'Ù…ØµØ·Ù„Ø­', 'Ù…ÙÙ‡ÙˆÙ…']):
                definition_sentences.append(sentence)
        
        if not definition_sentences:
            definition_sentences = sentences[:2]  # Ø£ÙˆÙ„ Ø¬Ù…Ù„ØªÙŠÙ†
        
        if detailed:
            return " ".join(definition_sentences[:4])  # 4 Ø¬Ù…Ù„ Ù„Ù„ØªÙØµÙŠÙ„
        else:
            return definition_sentences[0] if definition_sentences else sentences[0]
    
    def answer_how_to(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© (ÙƒÙŠÙ)"""
        sentences = self.split_into_sentences(content)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…Ù„ Ø§Ù„Ø®Ø·ÙˆØ§Øª ÙˆØ§Ù„Ø·Ø±Ù‚
        how_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['Ø®Ø·ÙˆØ©', 'Ø·Ø±ÙŠÙ‚Ø©', 'ÙƒÙŠÙÙŠØ©', 'ÙŠÙ…ÙƒÙ†', 'Ø£ÙˆÙ„Ø§Ù‹', 'Ø«Ø§Ù†ÙŠØ§Ù‹', 'Ø¹Ø¨Ø±', 'Ù…Ù† Ø®Ù„Ø§Ù„']):
                how_sentences.append(sentence)
        
        if not how_sentences:
            how_sentences = sentences[:3]
        
        if detailed:
            return " ".join(how_sentences[:5])
        else:
            return " ".join(how_sentences[:2])
    
    def answer_why(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø³Ø¨Ø¨ (Ù„Ù…Ø§Ø°Ø§)"""
        sentences = self.split_into_sentences(content)
        
        why_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['Ø³Ø¨Ø¨', 'Ù„Ø£Ù†', 'Ù†ØªÙŠØ¬Ø©', 'Ø¨Ø³Ø¨Ø¨', 'ÙŠØ¤Ø¯ÙŠ', 'ÙŠØ³Ø¨Ø¨', 'Ø§Ù„Ø³Ø¨Ø¨']):
                why_sentences.append(sentence)
        
        if not why_sentences:
            why_sentences = sentences[:2]
        
        if detailed:
            return " ".join(why_sentences[:4])
        else:
            return why_sentences[0] if why_sentences else sentences[0]
    
    def answer_when(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙˆÙ‚Øª (Ù…ØªÙ‰)"""
        sentences = self.split_into_sentences(content)
        
        when_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['Ø¹Ø§Ù…', 'ØªØ§Ø±ÙŠØ®', 'ÙŠÙˆÙ…', 'Ø´Ù‡Ø±', 'Ù‚Ø¨Ù„', 'Ø¨Ø¹Ø¯', 'ÙÙŠ', 'Ù…Ù†Ø°']):
                when_sentences.append(sentence)
        
        if not when_sentences:
            when_sentences = sentences[:2]
        
        return " ".join(when_sentences[:3 if detailed else 1])
    
    def answer_where(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ§Ù† (Ø£ÙŠÙ†)"""
        sentences = self.split_into_sentences(content)
        
        where_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['ÙÙŠ', 'Ø¨Ù€', 'ØªÙ‚Ø¹', 'ÙŠÙ‚Ø¹', 'Ù…ÙˆÙ‚Ø¹', 'Ù…ÙƒØ§Ù†', 'Ø¯ÙˆÙ„Ø©', 'Ù…Ø¯ÙŠÙ†Ø©']):
                where_sentences.append(sentence)
        
        if not where_sentences:
            where_sentences = sentences[:2]
        
        return " ".join(where_sentences[:3 if detailed else 1])
    
    def answer_who(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù‡ÙˆÙŠØ© (Ù…Ù†)"""
        sentences = self.split_into_sentences(content)
        
        who_sentences = []
        for sentence in sentences:
            if any(word in sentence for word in ['Ø´Ø®Øµ', 'Ø±Ø¬Ù„', 'Ø§Ù…Ø±Ø£Ø©', 'Ø¹Ø§Ù„Ù…', 'Ù…Ø¤Ù„Ù', 'Ø±Ø¦ÙŠØ³', 'Ù…Ø¯ÙŠØ±']):
                who_sentences.append(sentence)
        
        if not who_sentences:
            who_sentences = sentences[:2]
        
        return " ".join(who_sentences[:3 if detailed else 1])
    
    def answer_general(self, content, detailed):
        """Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ø§Ù…Ø© Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø£Ø®Ø±Ù‰"""
        sentences = self.split_into_sentences(content)
        
        if detailed:
            return " ".join(sentences[:5])
        else:
            return " ".join(sentences[:2])
    
    def split_into_sentences(self, text):
        """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø¬Ù…Ù„"""
        sentences = re.split(r'[.!ØŸ\?\n]+', text)
        clean_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 20:  # Ø¬Ù…Ù„ Ø°Ø§Øª Ù…Ø¹Ù†Ù‰
                clean_sentences.append(sentence)
        return clean_sentences[:10]  # Ø£ÙˆÙ„ 10 Ø¬Ù…Ù„ ÙÙ‚Ø·

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒÙŠØ©
smart_engine = SmartAnswerEngine()

STOP = set("""Ù…Ù† ÙÙŠ Ø¹Ù„Ù‰ Ø¥Ù„Ù‰ Ø¹Ù† Ø£Ù† Ø¥Ù† Ø¨Ø£Ù† ÙƒØ§Ù† ØªÙƒÙˆÙ† ÙŠÙƒÙˆÙ† Ø§Ù„ØªÙŠ Ø§Ù„Ø°ÙŠ Ø§Ù„Ø°ÙŠÙ† Ù‡Ø°Ø§ Ù‡Ø°Ù‡ Ø°Ù„Ùƒ Ù‡Ù†Ø§Ùƒ Ø«Ù… Ø­ÙŠØ« ÙƒÙ…Ø§ Ø§Ø°Ø§ Ø¥Ø°Ø§ Ø£Ùˆ Ùˆ ÙŠØ§ Ù…Ø§ Ù…Ø¹ Ù‚Ø¯ Ù„Ù… Ù„Ù† Ø¨ÙŠÙ† Ù„Ø¯Ù‰ Ù„Ø¯Ù‰ØŒ Ø¹Ù†Ø¯ Ø¨Ø¹Ø¯ Ù‚Ø¨Ù„ Ø¯ÙˆÙ† ØºÙŠØ± Ø­ØªÙ‰ ÙƒÙ„ Ø£ÙŠ ÙƒÙŠÙ Ù„Ù…Ø§Ø°Ø§ Ù…ØªÙ‰ Ù‡Ù„ Ø§Ù„Ù‰ Ø§Ù„""".split())

def tokenize(s: str):
    s = re.sub(r"[^\w\s\u0600-\u06FF]+", " ", s.lower())
    toks = [t for t in s.split() if t and t not in STOP]
    return toks

def score_sentences(text: str, query: str):
    sentences = re.split(r'(?<=[\.\!\?\ØŸ])\s+|\n+', text or "")
    q_terms = set(tokenize(query))
    scored = []
    for s in sentences:
        s2 = s.strip()
        if len(s2) < 25 or not is_arabic(s2, 8):
            continue
        terms = set(tokenize(s2))
        inter = q_terms & terms
        score = len(inter) + (len(s2) >= 80)
        if score > 0:
            scored.append((score, s2))
    scored.sort(reverse=True, key=lambda x: x[0])
    return [s for _, s in scored[:8]]

def summarize_from_text(text: str, query: str, max_sentences=3):
    sents = score_sentences(text, query)
    return " ".join(sents[:max_sentences]) if sents else ""

def domain_of(url: str):
    try:
        return urlparse(url).netloc.lower()
    except:
        return url

# -------- Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª (ØªØ¹Ù„Ù… Ø°Ø§ØªÙŠ Ø¨Ø³ÙŠØ·) --------
def get_scores():
    return cache.get("domain_scores", {}) or {}

def save_scores(scores):
    cache.set("domain_scores", scores, expire=0)

def bump_score(domain: str, delta: int):
    if not domain:
        return
    scores = get_scores()
    scores[domain] = scores.get(domain, 0) + delta
    save_scores(scores)

# -------- Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø§Øª --------
def fetch(url: str, timeout=3):
    r = requests.get(url, headers=HDRS, timeout=timeout)
    r.raise_for_status()
    return r.text

def fetch_and_extract(url: str, timeout=3):
    try:
        html_text = fetch(url, timeout=timeout)
        if not html_text or len(html_text.strip()) < 100:
            return "", ""
        
        # ØªÙ†Ø¸ÙŠÙ HTML Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¶Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        html_text = html_text.replace('\x00', '').replace('\x0b', '').replace('\x0c', '')
        html_text = ''.join(char for char in html_text if ord(char) >= 32 or char in '\n\r\t')
        
        try:
            doc = Document(html_text)
            content_html = doc.summary()
        except:
            # Ø¥Ø°Ø§ ÙØ´Ù„ readabilityØŒ Ø§Ø³ØªØ®Ø¯Ù… BeautifulSoup Ù…Ø¨Ø§Ø´Ø±Ø©
            soup = BeautifulSoup(html_text, "html.parser")
            # Ø£Ø®Ø° Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ÙÙ‚Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            content = soup.find_all(['p', 'article', 'div'], limit=10)
            content_html = ''.join(str(tag) for tag in content)
        
        soup = BeautifulSoup(content_html, "html.parser")
        text = soup.get_text(separator="\n")
        return html.unescape(text), html_text
    except Exception as e:
        print(f"error getting summary: {e}")
        return "", ""

# -------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± --------
PRICE_RE = re.compile(r"(?i)(US?\s*\$|USD|EUR|GBP|AED|SAR|EGP|QAR|KWD|OMR|Ø¯\.Ø¥|Ø±\.Ø³|Ø¬\.Ù…|Ø¯\.Ùƒ|Ø±\.Ù‚|Ø±\.Ø¹)\s*[\d\.,]+")
AR_NUM = str.maketrans("Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©", "0123456789")

def extract_price_from_html(html_text: str):
    if not html_text:
        return ""
    text = BeautifulSoup(html_text, "html.parser").get_text(separator=" ")
    text = text.translate(AR_NUM)
    m = PRICE_RE.search(text)
    return m.group(0).strip() if m else ""

def try_get_price(url: str):
    try:
        h = fetch(url, timeout=3)
        price = extract_price_from_html(h)
        if price:
            return price
        soup = BeautifulSoup(h, "html.parser")
        meta_price = soup.find(attrs={"itemprop": "price"}) or soup.find("meta", {"property":"product:price:amount"})
        if meta_price:
            val = meta_price.get("content") or meta_price.text
            if val and re.search(r"[\d\.,]", val):
                return val.strip()
        time.sleep(0.3)
        h2 = fetch(url, timeout=3)
        return extract_price_from_html(h2)
    except Exception:
        return ""

# ---------------- ÙˆØ§Ø¬Ù‡Ø© HTML ----------------
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="ar" dir="rtl" data-theme="light">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ - Ù…Ø¬Ø§Ù†ÙŠ</title>
  <style>
    :root {{
      --bg:#ffffff; --fg:#111; --muted:#666; --card:#f7f7f7; --accent:#0b63c6; --summary:#eef6ff;
    }}
    [data-theme="dark"] {{
      --bg:#0f172a; --fg:#e5e7eb; --muted:#9ca3af; --card:#111827; --accent:#60a5fa; --summary:#0b2942;
    }}
    body {{ background:var(--bg); color:var(--fg); font-family: Tahoma, Arial; padding:18px; max-width:960px; margin:auto; }}
    input[type=text], select {{ width:100%; padding:12px; font-size:16px; background:var(--card); color:var(--fg); border:1px solid #334155; border-radius:10px; }}
    button {{ padding:10px 18px; font-size:16px; margin-top:8px; border-radius:10px; border:1px solid #334155; background:var(--card); color:var(--fg); cursor:pointer; }}
    .row {{ display:flex; gap:10px; flex-wrap:wrap; }}
    .col {{ flex:1 1 200px; min-width:220px; }}
    .card {{ background:var(--card); padding:12px; border-radius:10px; }}
    .summary {{ background:var(--summary); padding:12px; border-radius:10px; margin-top:10px; }}
    a {{ color:var(--accent); text-decoration:none; }}
    h1 {{ margin-top:0; }}
    .note {{ color:var(--muted); font-size:13px; }}
    .fb {{ display:inline-flex; gap:8px; margin-top:8px; }}
    .btn-mini {{ padding:6px 10px; font-size:13px; border:1px solid #334155; border-radius:8px; background:var(--bg); color:var(--fg); cursor:pointer; }}
    .toolbar {{ display:flex; gap:10px; align-items:center; flex-wrap:wrap; }}
    .imggrid {{ display:grid; grid-template-columns: repeat(auto-fill, minmax(140px, 1fr)); gap:10px; }}
    .imgcard {{ overflow:hidden; border-radius:10px; border:1px solid #334155; }}
    .imgcard img {{ width:100%; height:140px; object-fit:cover; display:block; }}
  </style>
</head>
<body>
  <div class="toolbar">
    <h1 style="flex:1;">Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ â€” Ø¨Ø­Ø« / ØªÙ„Ø®ÙŠØµ / Ø£Ø³Ø¹Ø§Ø± / ØµÙˆØ± (Ù…Ø¬Ø§Ù†ÙŠ)</h1>
    <button onclick="toggleTheme()" title="Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù„ÙŠÙ„ÙŠ/Ø§Ù„Ù†Ù‡Ø§Ø±ÙŠ">ğŸŒ“ ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹</button>
  </div>

  <form method="post" class="row">
    <div class="col"><input type="text" name="question" placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø£Ùˆ Ø§Ø³Ù…/Ø·Ø±Ø§Ø² Ø§Ù„Ø³Ù„Ø¹Ø©..." required /></div>
    <div class="col">
      <select name="mode">
        <option value="summary">Ø¨Ø­Ø« & ØªÙ„Ø®ÙŠØµ</option>
        <option value="prices">Ø¨Ø­Ø« Ø£Ø³Ø¹Ø§Ø± (Ù…ØªØ§Ø¬Ø±)</option>
        <option value="images">Ø¨Ø­Ø« ØµÙˆØ±</option>
      </select>
    </div>
    <div class="col" style="max-width:140px;"><button type="submit">ØªÙ†ÙÙŠØ°</button></div>
  </form>

  {result_panel}

  <p class="note" style="margin-top:18px;">
    Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ğŸ‘/ğŸ‘ ÙŠØ­Ø³Ù‘Ù† ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØµØ§Ø¯Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§. Ø²Ø± Â«Ù†Ø³Ø® Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©Â» ÙŠÙ†Ø³Ø® Ø§Ù„Ù…Ù„Ø®Ù‘Øµ. Ø²Ø± Â«ØªØµØ¯ÙŠØ± PDFÂ» ÙŠÙ†Ø²Ù‘Ù„ Ù†Ø³Ø®Ø© Ù…Ø±ØªØ¨Ø© Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø©.
  </p>

<script>
// ÙˆØ¶Ø¹ Ù„ÙŠÙ„ÙŠ/Ù†Ù‡Ø§Ø±ÙŠ
(function(){{
  const saved = localStorage.getItem("theme");
  if(saved){{ document.documentElement.setAttribute("data-theme", saved); }}
}})();
function toggleTheme(){{
  const cur = document.documentElement.getAttribute("data-theme") || "light";
  const next = cur === "light" ? "dark" : "light";
  document.documentElement.setAttribute("data-theme", next);
  localStorage.setItem("theme", next);
}}

// Ù†Ø³Ø® Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
async function copyAnswer(text){{
  try{{
    await navigator.clipboard.writeText(text || "");
    alert("ØªÙ… Ù†Ø³Ø® Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©!");
  }}catch(e){{ alert("ØªØ¹Ø°Ù‘Ø± Ø§Ù„Ù†Ø³Ø®. Ø±Ø¨Ù…Ø§ Ø§Ù„Ù…ØªØµÙØ­ ÙŠÙ…Ù†Ø¹Ù‡."); }}
}}

// Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚ÙŠÙŠÙ…
async function sendFeedback(domain, delta){{
  try{{
    const fd = new FormData();
    fd.append("domain", domain);
    fd.append("delta", delta.toString());
    const r = await fetch("/feedback", {{method:"POST", body: fd}});
    if(r.ok){{ /* Ø§Ø®ØªÙŠØ§Ø±ÙŠ: Ø±Ø³Ø§Ù„Ø© */ }}
  }}catch(e){{ console.log(e); }}
}}
</script>
</body>
</html>
"""

def feedback_buttons(domain: str):
    d = html.escape(domain or "")
    return f'''
      <div class="fb">
        <button class="btn-mini" onclick="sendFeedback('{d}', 1)">ğŸ‘ Ù…ÙÙŠØ¯</button>
        <button class="btn-mini" onclick="sendFeedback('{d}', -1)">ğŸ‘ ØºÙŠØ± Ø¯Ù‚ÙŠÙ‚</button>
      </div>
    '''

def make_summary_card(title, url, summ, domain):
    return (
        f'<div class="card" style="margin-top:10px;"><strong>{html.escape(title)}</strong>'
        f'<div class="summary" style="margin-top:8px;">{html.escape(summ)}</div>'
        f'<div style="margin-top:8px;"><a target="_blank" href="{html.escape(url)}">ÙØªØ­ Ø§Ù„Ù…ØµØ¯Ø±</a></div>'
        f'{feedback_buttons(domain)}'
        f'</div>'
    )

def make_price_card(title, url, price, snippet, domain):
    price_html = f"<div><strong>Ø§Ù„Ø³Ø¹Ø±:</strong> {html.escape(price)}</div>" if price else "<div>Ø§Ù„Ø³Ø¹Ø± ØºÙŠØ± ÙˆØ§Ø¶Ø­ â€“ Ø§ÙØªØ­ Ø§Ù„Ù…ØµØ¯Ø± Ù„Ù„ØªØ­Ù‚Ù‚.</div>"
    sn = f'<div class="note" style="margin-top:6px;">{html.escape((snippet or "")[:180])}</div>' if snippet else ""
    return (
        f'<div class="card" style="margin-top:10px;"><strong>{html.escape(title)}</strong>'
        f'{price_html}'
        f'<div style="margin-top:8px;"><a target="_blank" href="{html.escape(url)}">ÙØªØ­ Ø§Ù„Ù…ØµØ¯Ø±</a></div>'
        f'{sn}'
        f'{feedback_buttons(domain)}'
        f'</div>'
    )

def make_toolbar_copy_pdf(q: str, mode: str, answer_text: str):
    pdf_url = "/export_pdf?" + urlencode({"q": q, "mode": mode})
    safe_answer_js = (answer_text or "").replace("\\", "\\\\").replace("'", "\\'").replace("\n", "\\n")
    return (
        f'<div class="row" style="margin-top:10px;">'
        f'  <div class="col" style="max-width:220px;"><button onclick="copyAnswer(\'{safe_answer_js}\'); return false;">ğŸ“‹ Ù†Ø³Ø® Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©</button></div>'
        f'  <div class="col" style="max-width:220px;"><a href="{pdf_url}" target="_blank"><button type="button">ğŸ–¨ï¸ ØªØµØ¯ÙŠØ± PDF</button></a></div>'
        f'</div>'
    )

# ---------------- Ø£ÙˆÙ„ÙˆÙŠØ© Ø°ÙƒÙŠØ© ----------------
def priority_key(item, mode="summary"):
    scores = get_scores()
    d = domain_of(item.get("href") or item.get("link") or item.get("url") or "")
    base = 2
    if d in PREFERRED_AR_DOMAINS: base -= 1
    if mode == "prices" and any(d.endswith(ms) or d==ms for ms in MARKET_SITES): base -= 0.5
    base -= 0.05 * scores.get(d, 0)
    return base

# ---------------- Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ----------------
@app.get("/", response_class=HTMLResponse)
async def form_get():
    return HTML_TEMPLATE.format(result_panel="")

@app.post("/", response_class=HTMLResponse)
async def form_post(question: str = Form(...), mode: str = Form("summary")):
    q = (question or "").strip()
    if not q:
        return HTML_TEMPLATE.format(result_panel="")

    if mode == "prices":
        panel, answer_text = await handle_prices(q, return_plain=True)
    elif mode == "images":
        panel, answer_text = await handle_images(q)
    else:
        panel, answer_text = await handle_summary(q, return_plain=True)

    # Ø´Ø±ÙŠØ· Ø£Ø¯ÙˆØ§Øª Ù†Ø³Ø® + PDF
    tools = make_toolbar_copy_pdf(q, mode, answer_text or "")
    return HTML_TEMPLATE.format(result_panel=tools + panel)

@app.post("/feedback")
async def feedback(domain: str = Form(...), delta: int = Form(...)):
    bump_score(domain, int(delta))
    return JSONResponse({"ok": True, "domain": domain, "score": get_scores().get(domain, 0)})

# -------- ÙˆØ¶Ø¹: Ø¨Ø­Ø« & ØªÙ„Ø®ÙŠØµ Ø¹Ø±Ø¨ÙŠ --------
async def handle_summary(q: str, return_plain=False):
    cache_key = "sum:" + q
    cached = cache.get(cache_key)
    if cached and not return_plain:
        return cached, ""

    query_ar = q if "Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in q else (q + " Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    with DDGS() as ddgs:
        results = list(ddgs.text(query_ar, region="xa-ar", safesearch="Moderate", max_results=25)) or []
    if not results:
        with DDGS() as ddgs:
            results = list(ddgs.text(query_ar, region="sa-ar", safesearch="Moderate", max_results=25)) or []
    if not results:
        with DDGS() as ddgs:
            results = list(ddgs.text(q, region="xa-ar", safesearch="Moderate", max_results=25)) or []

    source_cards, combined_chunks = [], []
    for r in sorted(results, key=lambda it: priority_key(it, "summary")):
        href = r.get("href") or r.get("link") or r.get("url")
        title = r.get("title") or ""
        if not href:
            continue
        d = domain_of(href)

        ckey = "url:" + href
        val = cache.get(ckey)
        if val is None:
            txt, raw = fetch_and_extract(href)
            if txt and len(txt) > 200:
                cache.set(ckey, (txt, raw), expire=60*60*24)
            val = (txt, raw)
        page_text, raw_html = val

        if not page_text or not is_arabic(page_text):
            continue

        summ = summarize_from_text(page_text, q, max_sentences=3)
        if not summ:
            continue

        combined_chunks.append(summ)
        source_cards.append(make_summary_card(title, href, summ, d))
        if len(source_cards) >= 4:
            break

    if not combined_chunks:
        panel = '<div class="card" style="margin-top:12px;">Ù„Ù… Ø£Ø¹Ø«Ø± Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ ÙƒØ§ÙÙ. ØºÙŠÙ‘Ø± ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø£Ùˆ Ø£Ø¶Ù ÙƒÙ„Ù…Ø© "Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©".</div>'
        cache.set(cache_key, panel, expire=60*5)
        return (panel, "") if return_plain else (panel, None)

    final_answer = " ".join(combined_chunks)
    panel = (
        f'<div style="margin-top:18px;">'
        f'<h3>Ø³Ø¤Ø§Ù„Ùƒ:</h3><div class="card">{html.escape(q)}</div>'
        f'<h3 style="margin-top:12px;">Ø§Ù„Ù…Ù„Ø®Ù‘Øµ (Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±):</h3><div class="summary">{html.escape(final_answer)}</div>'
        f'<h3 style="margin-top:12px;">Ø§Ù„Ù…ØµØ§Ø¯Ø±:</h3>'
        f'{"".join(source_cards)}'
        f'</div>'
    )
    cache.set(cache_key, panel, expire=60*60)
    return (panel, final_answer) if return_plain else (panel, None)

# -------- ÙˆØ¶Ø¹: Ø¨Ø­Ø« Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…ØªØ§Ø¬Ø± --------
async def handle_prices(q: str, return_plain=False):
    cache_key = "price:" + q
    cached = cache.get(cache_key)
    if cached and not return_plain:
        return cached, ""

    sites_filter = " OR ".join([f"site:{s}" for s in MARKET_SITES])
    query = f'{q} {sites_filter}'
    with DDGS() as ddgs:
        results = list(ddgs.text(query, region="xa-ar", safesearch="Off", max_results=30)) or []
    if not results:
        with DDGS() as ddgs:
            results = list(ddgs.text(q + " " + sites_filter, region="wt-wt", safesearch="Off", max_results=30)) or []

    cards, seen = [], set()
    lines_for_pdf = []
    for r in sorted(results, key=lambda it: priority_key(it, "prices")):
        url = r.get("href") or r.get("link") or r.get("url")
        title = r.get("title") or ""
        snippet = r.get("body") or ""
        if not url or url in seen:
            continue
        seen.add(url)
        d = domain_of(url)

        price = ""
        try:
            ckey = "purl:" + url
            html_page = cache.get(ckey)
            if html_page is None:
                html_page = fetch(url, timeout=3)
                if html_page and len(html_page) < 1_500_000:
                    cache.set(ckey, html_page, expire=60*60*6)
            price = extract_price_from_html(html_page or "")
            if not price and d.endswith("aliexpress.com"):
                soup = BeautifulSoup(html_page or "", "html.parser")
                meta_price = soup.find(attrs={"itemprop": "price"})
                if meta_price:
                    price = (meta_price.get("content") or meta_price.text or "").strip()
        except Exception:
            price = ""

        cards.append(make_price_card(title, url, price, snippet, d))
        lines_for_pdf.append(f"- {title} | {price or 'â€”'} | {url}")
        if len(cards) >= 10:
            break

    if not cards:
        panel = '<div class="card" style="margin-top:12px;">Ù„Ù… Ø£Ø¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙŠ Ø§Ù„Ù…ØªØ§Ø¬Ø±. Ø¬Ø±Ù‘Ø¨ Ø§Ø³Ù…Ù‹Ø§ Ø£Ø¯Ù‚ Ù„Ù„Ù…Ù†ØªØ¬ (Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„/Ø§Ù„Ø·Ø±Ø§Ø²) Ø£Ùˆ Ø£Ø¶Ù site:aliexpress.com.</div>'
        cache.set(cache_key, panel, expire=60*5)
        return (panel, "") if return_plain else (panel, None)

    # Ù†Øµ Ø¨Ø³ÙŠØ· Ù„Ù„ØªØµØ¯ÙŠØ±/Ø§Ù„Ù†Ø³Ø®
    answer_text = "Ù†ØªØ§Ø¦Ø¬ Ø£Ø³Ø¹Ø§Ø±:\n" + "\n".join(lines_for_pdf)
    panel = f'<div style="margin-top:18px;"><h3>Ø¨Ø­Ø« Ø£Ø³Ø¹Ø§Ø± Ø¹Ù†: {html.escape(q)}</h3>{"".join(cards)}</div>'
    cache.set(cache_key, panel, expire=60*30)
    return (panel, answer_text) if return_plain else (panel, None)

# -------- ÙˆØ¶Ø¹: Ø¨Ø­Ø« Ø§Ù„ØµÙˆØ± --------
async def handle_images(q: str):
    key = "img:" + q
    cached = cache.get(key)
    if cached:
        return cached, ""

    items = []
    try:
        if DDGS:
            with DDGS() as dd:
                for it in dd.images(keywords=q, region="xa-ar", safesearch="Off", max_results=20):
                    items.append({"title": it.get("title") or "", "image": it.get("image"), "source": it.get("url")})
        else:
            # Ø§Ø­ØªÙŠØ§Ø·: Ø§Ø³ØªØ®Ø¯Ù… Ø¨Ø­Ø« ÙˆÙŠØ¨ Ø¹Ø§Ø¯ÙŠ Ù…Ø¹ "ØµÙˆØ±"
            with DDGS() as ddgs:
                results = list(ddgs.text(q + " ØµÙˆØ±", region="xa-ar", safesearch="Off", max_results=20)) or []
            for r in results:
                items.append({"title": r.get("title") or "", "image": None, "source": r.get("href") or r.get("url")})
    except Exception:
        items = []

    if not items:
        panel = '<div class="card" style="margin-top:12px;">Ù„Ù… Ø£Ø¬Ø¯ ØµÙˆØ±Ù‹Ø§ Ù…Ù†Ø§Ø³Ø¨Ø©. Ø­Ø§ÙˆÙ„ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø± Ø£Ùˆ ÙƒÙ„Ù…Ø© "ØµÙˆØ±".</div>'
        cache.set(key, (panel, ""), expire=60*10)
        return panel, ""

    cards = []
    for it in items[:16]:
        img = it.get("image")
        src = it.get("source")
        title = it.get("title") or ""
        if img:
            cards.append(f'<div class="imgcard"><a href="{html.escape(src or img)}" target="_blank"><img src="{html.escape(img)}" alt=""/></a></div>')
        else:
            # Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØµÙˆØ±Ø© Ù…Ø¨Ø§Ø´Ø±Ø©â€”Ù†Ø¹Ø±Ø¶ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø±
            cards.append(f'<div class="card"><a href="{html.escape(src)}" target="_blank">{html.escape(title or "ÙØªØ­ Ø§Ù„Ù…ØµØ¯Ø±")}</a></div>')

    panel = f'<div style="margin-top:18px;"><h3>Ù†ØªØ§Ø¦Ø¬ ØµÙˆØ± Ø¹Ù†: {html.escape(q)}</h3><div class="imggrid">{"".join(cards)}</div></div>'
    cache.set(key, (panel, ""), expire=60*20)
    return panel, ""

# -------- ØªØµØ¯ÙŠØ± PDF --------
@app.get("/export_pdf")
def export_pdf(q: str, mode: str = "summary"):
    """
    ÙŠØ¨Ù†ÙŠ PDF Ø¨Ø³ÙŠØ· Ù…Ù† Ø¢Ø®Ø± Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„ÙƒØ§Ø´ (Ø­Ø³Ø¨ q + mode).
    - Ù„Ù„Ù…Ù„Ø®Øµ: ÙŠØ³ØªØ®Ø±Ø¬ Ù†Øµ Ø§Ù„Ù…Ù„Ø®Øµ ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø± Ù…Ù† Ø§Ù„Ù€ panel Ø§Ù„Ù…Ø®Ø²Ù†.
    - Ù„Ù„Ø£Ø³Ø¹Ø§Ø±: ÙŠØ³Ø±Ø¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†/Ø§Ù„Ø£Ø³Ø¹Ø§Ø±/Ø§Ù„Ø±ÙˆØ§Ø¨Ø·.
    """
    if mode == "prices":
        panel, ans = handle_prices_sync(q)
        text_for_pdf = ans or "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª."
        title = f"Ø¨Ø­Ø« Ø£Ø³Ø¹Ø§Ø±: {q}"
    elif mode == "images":
        panel = cache.get("img:" + q)
        title = f"Ù†ØªØ§Ø¦Ø¬ ØµÙˆØ±: {q}"
        text_for_pdf = f"Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù†Ø§ØµØ±: {len(panel[0]) if panel else 0}\n(ÙŠÙÙ†ØµØ­ Ø¨ÙØªØ­ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ù…ØªØµÙØ­ Ù„Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„ØµÙˆØ±)"
    else:
        panel_html = cache.get("sum:" + q)
        if not panel_html:
            # Ø­Ø§ÙˆÙ„ ØªÙˆÙ„ÙŠØ¯ Ø³Ø±ÙŠØ¹ Ø«Ù… Ø§Ø³ØªØ®Ø¯Ù…Ù‡
            p, ans = app.run_sync(handle_summary(q, return_plain=True))  # Ù‚Ø¯ Ù„Ø§ ÙŠØ¹Ù…Ù„ ÙÙŠ Ø¨Ø¹Ø¶ Ø¨ÙŠØ¦Ø§Øª ASGIØŒ Ù„Ø°Ø§ Ù†Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ§Ø´ ÙÙŠ Ø§Ù„Ø¹Ø§Ø¯Ø©
            panel_html = p
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„Ø®Øµ ÙƒÙ†Øµ Ù…Ù† Ø§Ù„Ù€ HTML
        soup = BeautifulSoup(panel_html or "", "html.parser")
        summary_div = soup.find("div", {"class": "summary"})
        text_for_pdf = summary_div.get_text(" ", strip=True) if summary_div else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª."
        title = f"Ù…Ù„Ø®Øµ Ø§Ù„Ø¨Ø­Ø«: {q}"

    pdf = FPDF()
    pdf.add_page()
    pdf.add_font('Arial', '', fname='')
    pdf.set_font("Arial", size=14)
    pdf.multi_cell(0, 10, title)
    pdf.ln(4)
    pdf.set_font("Arial", size=12)
    for line in (text_for_pdf or "").split("\n"):
        pdf.multi_cell(0, 8, line)

    pdf_bytes = pdf.output(dest="S").encode("latin1", "ignore")
    headers = {
        "Content-Disposition": f'attachment; filename="bassam_ai_{mode}.pdf"',
        "Content-Type": "application/pdf",
    }
    return Response(content=pdf_bytes, headers=headers)

# Ù†Ø³Ø®Ø© Ù…ØªØ²Ø§Ù…Ù†Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø³Ø¹Ø±ÙŠ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ PDF Ù„Ùˆ Ø§Ø­ØªØ¬Ù†Ø§
def handle_prices_sync(q: str):
    sites_filter = " OR ".join([f"site:{s}" for s in MARKET_SITES])
    query = f'{q} {sites_filter}'
    with DDGS() as ddgs:
        results = list(ddgs.text(query, region="xa-ar", safesearch="Off", max_results=15)) or []
    if not results:
        with DDGS() as ddgs:
            results = list(ddgs.text(q + " " + sites_filter, region="wt-wt", safesearch="Off", max_results=15)) or []
    lines = []
    for r in results[:10]:
        url = r.get("href") or r.get("link") or r.get("url")
        title = r.get("title") or ""
        price = ""
        try:
            h = fetch(url, timeout=3)
            price = extract_price_from_html(h)
        except Exception:
            pass
        lines.append(f"- {title} | {price or 'â€”'} | {url}")
    panel = ""  # ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù… Ù‡Ù†Ø§
    return panel, "Ù†ØªØ§Ø¦Ø¬ Ø£Ø³Ø¹Ø§Ø±:\n" + "\n".join(lines)

@app.get("/health")
def health():
    return {"ok": True}