# main.py â€” Bassam Ø§Ù„Ø°ÙƒÙŠ v3.7 (RAG + Math + Web + Self-Learning + Emotion + Friendly Persona)
from fastapi import FastAPI, Request, Query, Body
from fastapi.responses import HTMLResponse, RedirectResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware

import os, json, time, re
from typing import List, Dict, Any

# ğŸ§  Ù…Ø´Ø§Ø¹Ø±
from textblob import TextBlob

# === Ù†ØµÙŠ ÙˆØªÙ„Ø®ÙŠØµ ===
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS
from readability import Document

# sumy (Ø¥ØµØ¯Ø§Ø± 0.11.0 Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ plaintext)
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer

# === Ø±ÙŠØ§Ø¶ÙŠØ§Øª ===
from sympy import symbols, sympify, diff, integrate, simplify, sin, cos, tan, log, exp

# === ÙÙ‡Ø±Ø³Ø© RAG Ù…Ø­Ù„ÙŠØ© (BM25) ===
from rank_bm25 import BM25Okapi

DATA_DIR = "data"
NOTES_DIR = os.path.join(DATA_DIR, "notes")
LEARN_PATH = os.path.join(NOTES_DIR, "learned.jsonl")
USAGE_PATH = os.path.join(DATA_DIR, "usage_stats.json")

app = FastAPI(title="Bassam Ø§Ù„Ø°ÙƒÙŠ ğŸ¤–", version="3.7")

# Ø±Ø¨Ø· Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
try:
    app.mount("/static", StaticFiles(directory="static"), name="static")
    templates = Jinja2Templates(directory="templates")
except Exception:
    templates = None

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

# =========================
# Ø´Ø®ØµÙŠØ© ÙˆØ±Ø¯ÙˆØ¯ ÙˆØ¯Ù‘ÙŠØ©
# =========================
PERSONALITY = {
    "greeting": "Ø£Ù‡Ù„Ù‹Ø§ Ø¨ØµØ§Ø­Ø¨ÙŠ! ğŸ˜Š Ø£Ù†Ø§ Ø¨Ø³Ù‘Ø§Ù… Ø§Ù„Ø°ÙƒÙŠØŒ Ø­Ø§Ø¶Ø± Ù„Ø£ÙŠ Ù…Ø³Ø§Ø¹Ø¯Ø©.",
    "neutral": "ØªÙ…Ø§Ù…ØŒ Ù‡Ø°Ø§ Ø±Ø£ÙŠÙŠ Ø¨Ø§Ø®ØªØµØ§Ø±:",
    "positive": "ÙŠØ§ Ø³Ù„Ø§Ù…! Ù…ØªÙØ§Ø¦Ù„ ÙˆÙ‡Ø°Ø§ Ø´ÙŠØ¡ Ø¬Ù…ÙŠÙ„ âœ¨\nØ¥Ù„ÙŠÙƒ Ø§Ù„Ø®Ù„Ø§ØµØ©:",
    "negative": "Ø­Ø§Ø¶Ø±ØŒ Ù…Ø¹Ùƒ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©â€”Ø®Ù„ÙŠÙ†Ø§ Ù†Ø³Ù‡Ù„Ù‡Ø§ Ø³ÙˆØ§ ğŸŒ¤ï¸\nØ§Ù„Ø®Ù„Ø§ØµØ©:",
    "closing": "Ù„Ùˆ ØªØ­Ø¨ Ø£ØªØ¹Ù…Ù‘Ù‚ Ø£ÙƒØ«Ø± Ø£Ùˆ Ø£Ø¹Ø·ÙŠÙƒ Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠØŒ Ù‚Ù„Ù‘ÙŠ ğŸ’¡"
}

def analyze_emotion_text(text: str) -> str:
    try:
        polarity = TextBlob(text).sentiment.polarity
        if polarity > 0.3: return "positive"
        if polarity < -0.3: return "negative"
        return "neutral"
    except Exception:
        return "neutral"

def decorate_answer(emotion: str, core: str) -> str:
    header = PERSONALITY["greeting"] + "\n"
    if emotion == "positive":
        tone = PERSONALITY["positive"]
    elif emotion == "negative":
        tone = PERSONALITY["negative"]
    else:
        tone = PERSONALITY["neutral"]
    return f"{header}{tone}\n\n{core}\n\n{PERSONALITY['closing']}"

# =========================
# ØªÙ‡ÙŠØ¦Ø© ÙˆÙÙ‡Ø±Ø³Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# =========================
def _ensure_dirs():
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(NOTES_DIR, exist_ok=True)
    if not os.path.exists(LEARN_PATH):
        open(LEARN_PATH, "a", encoding="utf-8").close()
    if not os.path.exists(USAGE_PATH):
        with open(USAGE_PATH, "w", encoding="utf-8") as f:
            json.dump({"requests": 0, "last_time": int(time.time())}, f)
_ensure_dirs()

def _read_md_txt_files() -> List[Dict[str, str]]:
    docs = []
    for root, _, files in os.walk(DATA_DIR):
        for fn in files:
            if fn.endswith(".md") or fn.endswith(".txt"):
                path = os.path.join(root, fn)
                try:
                    with open(path, "r", encoding="utf-8", errors="ignore") as f:
                        docs.append({"file": path, "text": f.read()})
                except:
                    pass
    # Ø¶Ù… Ø¨Ù†Ùƒ Ø§Ù„ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ø°Ø§ØªÙŠ
    try:
        with open(LEARN_PATH, "r", encoding="utf-8") as f:
            for line in f:
                if not line.strip(): continue
                obj = json.loads(line)
                text = f"Ø³: {obj.get('question','')}\nØ¬: {obj.get('answer','')}\nÙˆØ³ÙˆÙ…:{','.join(obj.get('tags',[]))}"
                docs.append({"file": "learned", "text": text})
    except:
        pass
    return docs

def _tokenize_ar(s: str) -> List[str]:
    return re.findall(r"[\w\u0600-\u06FF]+", s.lower())

BM25_INDEX = None
BM25_CORPUS = []
BM25_DOCS: List[Dict[str, str]] = []

def build_index():
    global BM25_INDEX, BM25_CORPUS, BM25_DOCS
    BM25_DOCS = _read_md_txt_files()
    BM25_CORPUS = [_tokenize_ar(d["text"]) for d in BM25_DOCS]
    BM25_INDEX = BM25Okapi(BM25_CORPUS) if BM25_CORPUS else None
    return len(BM25_DOCS)

build_index()

# =========================
# Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡
# =========================
def summarize_text(text: str, max_sentences: int = 3) -> str:
    try:
        parser = PlaintextParser.from_string(text, Tokenizer("arabic"))
        summ = TextRankSummarizer()
        sents = summ(parser.document, max_sentences)
        return " ".join(str(s) for s in sents) if sents else text[:400]
    except Exception:
        return text[:400]

def web_search(query: str):
    try:
        # Ø¬Ø±Ù‘Ø¨ Ø¹Ø§Ù„Ù…ÙŠØ© Ø£ÙˆÙ„Ù‹Ø§ Ø«Ù… Ø¹Ø±Ø¨ÙŠØ© ÙƒÙ€ fallback
        with DDGS() as ddgs:
            res = list(ddgs.text(query, region="wt-wt", max_results=5))
        if not res:
            with DDGS() as ddgs:
                res = list(ddgs.text(query, region="xa-ar", max_results=5))
        return [{"title": r.get("title",""), "link": r.get("href",""), "snippet": r.get("body","")} for r in res[:5]]
    except Exception:
        return []

def rag_bm25(query: str, k: int = 3):
    if not BM25_INDEX: return []
    toks = _tokenize_ar(query)
    scores = BM25_INDEX.get_scores(toks)
    pairs = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:k]
    results = []
    for idx, sc in pairs:
        if sc < 1.0: continue
        doc = BM25_DOCS[idx]
        snippet = doc["text"][:600]
        results.append({"file": doc["file"], "score": float(sc), "snippet": snippet})
    return results

def solve_math(expr: str):
    try:
        x = symbols('x')
        parsed = sympify(expr)
        return {
            "input": str(parsed),
            "simplified": str(simplify(parsed)),
            "derivative": str(diff(parsed, x)),
            "integral": str(integrate(parsed, x)),
        }
    except Exception as e:
        return {"error": f"ØªØ¹Ø°Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©: {e}"}

def log_usage():
    try:
        with open(USAGE_PATH, "r+", encoding="utf-8") as f:
            data = json.load(f)
            data["requests"] = int(data.get("requests", 0)) + 1
            data["last_time"] = int(time.time())
            f.seek(0); json.dump(data, f); f.truncate()
    except Exception:
        pass

def save_feedback(question: str, answer: str, tags: List[str]):
    record = {"time": int(time.time()), "question": question.strip(), "answer": answer.strip(), "tags": tags or []}
    with open(LEARN_PATH, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")

# =========================
# ÙˆØ§Ø¬Ù‡Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# =========================
@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    if templates and os.path.exists("templates/index.html"):
        return templates.TemplateResponse("index.html", {"request": request, "version": "v3.7"})
    html = """<!doctype html><meta charset='utf-8'><title>Bassam AI</title>
    <style>body{background:#0b1020;color:#e7ecff;font-family:system-ui;text-align:center;margin-top:40px}
    input,button{padding:10px;border-radius:10px;border:1px solid #223066;background:#0f1a38;color:#fff}
    pre{text-align:left;max-width:800px;margin:auto;background:#141b2e;padding:10px;border-radius:8px}</style>
    <h2>ğŸ¤– Ø¨Ø³Ù‘Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„ÙˆØ¯ÙˆØ¯ v3.7 â¤ï¸</h2><input id=q style='width:60%' placeholder='Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ'><button onclick='ask()'>Ø¥Ø±Ø³Ø§Ù„</button>
    <pre id=out></pre><script>
    async function ask(){const q=document.getElementById('q').value;
    const r=await fetch('/ask?q='+encodeURIComponent(q));const j=await r.json();
    document.getElementById('out').textContent=JSON.stringify(j,null,2);}
    </script>"""
    return HTMLResponse(html)

# alias Ù„Ù…Ø³Ø§Ø± Ù‚Ø¯ÙŠÙ…
@app.get("/chatui")
@app.get("/chatui/")
def chatui_alias():
    return RedirectResponse(url="/")

@app.get("/healthz")
def healthz():
    return {"status": "ok", "version": "3.7", "docs_indexed": len(BM25_DOCS)}

# ØªÙˆØ­ÙŠØ¯ Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
def _answer(q: str) -> Dict[str, Any]:
    emotion = analyze_emotion_text(q)

    # Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø£ÙˆÙ„Ø§Ù‹
    if any(tok in q for tok in ["sin", "cos", "tan", "log", "exp", "^"]) or "Ù…Ø´ØªÙ‚Ø©" in q or "ØªÙƒØ§Ù…Ù„" in q:
        core = "Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§ØªÙŠØ© Ù…ÙØ±ÙÙ‚Ø©."
        return {"type": "math", "emotion": emotion, "message": decorate_answer(emotion, core), "result": solve_math(q)}

    # RAG Ù…Ø­Ù„ÙŠ
    rag = rag_bm25(q, k=3)
    if rag:
        s = summarize_text(rag[0]["snippet"], 3)
        core = f"Ù…Ù„Ø®Ù‘Øµ Ù…Ù† Ù…Ù„ÙØ§ØªÙƒ:\n{s}"
        return {"type": "rag", "emotion": emotion, "message": decorate_answer(emotion, core), "hits": rag, "summary": s}

    # Ø¨Ø­Ø« ÙˆÙŠØ¨
    web = web_search(q)
    if web:
        for item in web: item["summary"] = summarize_text(item["snippet"], 2)
        core = "Ø¬Ù…Ø¹Øª Ù„Ùƒ Ù†ØªØ§Ø¦Ø¬ Ù…Ù† Ø§Ù„ÙˆÙŠØ¨ Ù…Ø¹ ØªÙ„Ø®ÙŠØµ Ø³Ø±ÙŠØ¹."
        return {"type": "web", "emotion": emotion, "message": decorate_answer(emotion, core), "results": web}

    # Ù„Ø§ Ù†ØªØ§Ø¦Ø¬
    core = "Ù„Ù… Ø£Ø¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© Ø¯Ù‚ÙŠÙ‚Ø© Ø§Ù„Ø¢Ù†. Ø¬Ø±Ù‘Ø¨ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø£Ùˆ Ø²ÙˆÙ‘Ø¯Ù†ÙŠ Ø¨ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø±."
    return {"type": "none", "emotion": emotion, "message": decorate_answer(emotion, core)}

@app.get("/ask")
def ask_get(q: str = Query(..., description="Ø³Ø¤Ø§Ù„Ùƒ")):
    q = (q or "").strip()
    if not q: return {"error": "Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ùƒ"}
    log_usage()
    return _answer(q)

@app.post("/ask")
def ask_post(payload: Dict[str, Any] = Body(...)):
    q = (payload.get("q") or payload.get("query") or payload.get("question") or "").strip()
    if not q: return {"error": "Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ùƒ"}
    log_usage()
    return _answer(q)

@app.post("/feedback")
def feedback(payload: Dict[str, Any] = Body(...)):
    q = (payload.get("question") or "").strip()
    a = (payload.get("answer") or "").strip()
    tags = payload.get("tags") or []
    if not q or not a:
        return {"ok": False, "error": "question Ùˆ answer Ù…Ø·Ù„ÙˆØ¨Ø©"}
    save_feedback(q, a, tags)
    n = build_index()
    return {"ok": True, "indexed_docs": n}

@app.post("/train")
def train():
    n = build_index()
    return {"ok": True, "indexed_docs": n}

@app.get("/stats")
def stats():
    try:
        with open(USAGE_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {"requests": 0}

if __name__ == "__main__":
    import uvicorn, os
    uvicorn.run("main:app", host="0.0.0.0", port=int(os.environ.get("PORT", 8000)))
