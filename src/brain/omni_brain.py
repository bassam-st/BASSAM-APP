import os, re, math, json, time
from datetime import datetime
from dateutil import parser as dateparser
from typing import List, Dict, Optional

import httpx
from bs4 import BeautifulSoup
from readability import Document
from duckduckgo_search import DDGS
from diskcache import Cache
from wikipedia import summary as wiki_summary

from sympy import sympify, diff, integrate
from sumy.parsers.plaintext import PlainTextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø© =====
UA = {"User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/124 Safari/537.36"}
cache = Cache(".cache")

# Gemini (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
USE_GEMINI = bool(os.getenv("GEMINI_API_KEY"))
if USE_GEMINI:
    import google.generativeai as genai
    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    GEMINI = genai.GenerativeModel("gemini-1.5-flash")
else:
    GEMINI = None

# ===== Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ù†ØµÙŠØ© =====
AR = lambda s: re.sub(r"\s+", " ", (s or "").strip())

# ===== ØªÙ„Ø®ÙŠØµ Ù…Ø­Ù„ÙŠ =====
def summarize_text(text: str, max_sentences: int = 5) -> str:
    try:
        parser = PlainTextParser.from_string(text, Tokenizer("arabic"))
        summ = TextRankSummarizer()
        sents = summ(parser.document, max_sentences)
        return " ".join(str(s) for s in sents)
    except Exception:
        return text[:700]

# ===== Ø¨Ø­Ø« Ø§Ù„ÙˆÙŠØ¨ =====
def ddg_text(q: str, n: int = 5) -> List[Dict]:
    with DDGS() as ddgs:
        return list(ddgs.text(q, region="xa-ar", safesearch="moderate", max_results=n) or [])

def fetch_clean(url: str, timeout: int = 12) -> str:
    try:
        r = httpx.get(url, headers=UA, timeout=timeout, follow_redirects=True)
        r.raise_for_status()
        doc = Document(r.text)
        html_clean = doc.summary()
        text = BeautifulSoup(html_clean, "lxml").get_text("\n", strip=True)
        return text[:8000]
    except Exception:
        return ""

# ===== Ø£Ø¯ÙˆØ§Øª Ù…Ø­Ù„ÙŠØ© (Ø±ÙŠØ§Ø¶ÙŠØ§Øª/ÙˆØ­Ø¯Ø§Øª/ØªÙˆØ§Ø±ÙŠØ®) =====
MATH_PAT = re.compile(r"[=+\-*/^()]|sin|cos|tan|log|sqrt|âˆ«|dx|dy|d/dx|Ù…Ø´ØªÙ‚Ø©|ØªÙƒØ§Ù…Ù„", re.I)
CURRENCY = {"USD":1.0, "EUR":0.92, "SAR":3.75, "AED":3.67, "YER":250.0}

def answer_math(q: str) -> Optional[str]:
    if not MATH_PAT.search(q):
        return None
    try:
        s = q.replace("^", "**")
        expr = sympify(s)
        return f"Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ: {expr.evalf()}"
    except Exception:
        if q.strip().startswith("Ù…Ø´ØªÙ‚Ø© "):
            t = q.split("Ù…Ø´ØªÙ‚Ø© ",1)[1]
            try: return f"Ù…Ø´ØªÙ‚Ø© {t} = {diff(sympify(t))}"
            except: return "Ù„Ù… Ø£ÙÙ‡Ù… Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ù„Ù„Ù…Ø´ØªÙ‚Ø©."
        if q.strip().startswith("ØªÙƒØ§Ù…Ù„ "):
            t = q.split("ØªÙƒØ§Ù…Ù„ ",1)[1]
            try: return f"ØªÙƒØ§Ù…Ù„ {t} = {integrate(sympify(t))}"
            except: return "Ù„Ù… Ø£ÙÙ‡Ù… Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ù„Ù„ØªÙƒØ§Ù…Ù„."
        return None

def answer_units_dates(q: str) -> Optional[str]:
    # Ø¹Ù…Ù„Ø© Ø¨Ø³ÙŠØ·Ø©: "100 USD Ø¥Ù„Ù‰ YER"
    m = re.search(r"(\d+[\.,]?\d*)\s*(USD|EUR|SAR|AED|YER)\s*(?:->|Ø§Ù„Ù‰|Ø¥Ù„Ù‰|to)\s*(USD|EUR|SAR|AED|YER)", q, re.I)
    if m:
        amount = float(m.group(1).replace(",", "."))
        src, dst = m.group(2).upper(), m.group(3).upper()
        usd = amount / CURRENCY[src]
        out = usd * CURRENCY[dst]
        return f"ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§: {amount} {src} â‰ˆ {round(out,2)} {dst}"
    # ØªØ§Ø±ÙŠØ®/ÙˆÙ‚Øª Ø¨Ø³ÙŠØ·: "Ù…Ø§ ØªØ§Ø±ÙŠØ® 3 Ø£ÙŠØ§Ù… Ø¨Ø¹Ø¯ 2025-09-27"
    m2 = re.search(r"(\d+)\s*(ÙŠÙˆÙ…|Ø£ÙŠØ§Ù…|day|days)\s*(?:Ø¨Ø¹Ø¯|later|from)\s*([0-9\-/: ]+)", q, re.I)
    if m2:
        n = int(m2.group(1)); base = dateparser.parse(m2.group(3))
        if base:
            return (base + __import__('datetime').timedelta(days=n)).strftime("%Y-%m-%d %H:%M")
    return None

# ===== ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§ Ù‚ØµÙŠØ±Ø© =====
def answer_wikipedia(q: str) -> Optional[str]:
    m = re.search(r"^(Ù…Ù† Ù‡Ùˆ|Ù…Ù† Ù‡ÙŠ|Ù…Ø§ Ù‡ÙŠ|Ù…Ø§Ù‡Ùˆ|Ù…Ø§Ù‡ÙŠ)\s+(.+)$", q.strip(), re.I)
    topic = m.group(2) if m else None
    topic = topic or (q if len(q.split())<=6 else None)
    if not topic:
        return None
    try:
        s = wiki_summary(topic, sentences=3, auto_suggest=False, redirect=True)
        return AR(s)
    except Exception:
        return None

# ===== Ù…Ø´Ø§Ø¹Ø± ÙˆØªØ­ÙŠØ§Øª (Ø´Ø®ØµÙŠØ© ÙˆØ¯ÙˆØ¯Ø©) =====
GREET_WORDS = [
    "Ù…Ø±Ø­Ø¨Ø§", "Ù…Ø±Ø­Ø¨Ø§Ù‹", "Ø§Ù‡Ù„Ø§Ù‹", "Ø£Ù‡Ù„Ø§Ù‹", "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…", "Ù‡Ù„Ø§", "ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±", "Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±",
    "Ù‡Ø§ÙŠ", "Ù‡ÙŽØ§ÙŠ", "Ø§Ø²ÙŠÙƒ", "Ø´Ù„ÙˆÙ†Ùƒ", "ÙƒÙŠÙÙƒ"
]
FAREWELL_WORDS = ["Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø©", "Ø¥Ù„Ù‰ Ø§Ù„Ù„Ù‚Ø§Ø¡", "ØªØµØ¨Ø­ Ø¹Ù„Ù‰ Ø®ÙŠØ±", "Ø§Ø´ÙˆÙÙƒ Ù„Ø§Ø­Ù‚Ø§Ù‹", "Ø¨Ø§ÙŠ"]

PERSONA_TAGLINES = [
    "Ø£Ù†Ø§ Ø¨Ø³Ù‘Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ â€” Ù‡Ù†Ø§ Ø¹Ø´Ø§Ù† Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø¨Ø®Ø·ÙˆØ§Øª Ø¨Ø³ÙŠØ·Ø© ÙˆÙˆØ§Ø¶Ø­Ø© âœ¨",
    "Ø¨Ø³Ù‘Ø§Ù… Ù…Ø¹Ùƒ! Ù†Ø­Ù„Ù‡Ø§ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© ÙˆØ¨Ù‡Ø¯ÙˆØ¡ ðŸ’ª",
]

def answer_empathy(q: str) -> Optional[str]:
    for w in GREET_WORDS:
        if w in q:
            return (
                "ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡ â€” Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! ðŸ˜Š\n"
                + PERSONA_TAGLINES[0]
            ) if "Ø§Ù„Ø³Ù„Ø§Ù…" in w else (
                "Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø³Ø¹ÙŠØ¯ Ø¨ÙˆØ¬ÙˆØ¯Ùƒ ðŸ¤\n" + PERSONA_TAGLINES[1]
            )
    for w in FAREWELL_WORDS:
        if w in q:
            return "ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù„Ù‡! Ø¥Ø°Ø§ Ø§Ø­ØªØ¬Øª Ø£ÙŠ Ø´ÙŠØ¡ Ø£Ù†Ø§ Ø­Ø§Ø¶Ø± Ø¯Ø§Ø¦Ù…Ù‹Ø§ ðŸŒŸ"
    if re.search(r"(Ø£Ù†Ø§ Ø­Ø²ÙŠÙ†|Ø­Ø²ÙŠÙ†Ù‡|Ù…ØªØ¶Ø§ÙŠÙ‚|Ù…ØªØ¶Ø§ÙŠÙ‚Ø©|Ù‚Ù„Ù‚Ø§Ù†|Ù‚Ù„Ù‚Ø§Ù†Ù‡|Ø²Ø¹Ù„Ø§Ù†)", q):
        return (
            "Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù…Ø¹Ùƒ ðŸ’™ â€” Ø®Ø° Ù†ÙØ³Ù‹Ø§ Ø¹Ù…ÙŠÙ‚Ù‹Ø§ØŒ ÙˆÙ‚Ù„ Ù„ÙŠ Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠØ²Ø¹Ø¬Ùƒ Ø®Ø·ÙˆØ© Ø®Ø·ÙˆØ©."
            " Ø£Ø¹Ø¯Ùƒ Ø£Ù†Ù†ÙŠ Ø³Ø£ÙƒÙˆÙ† Ù„Ø·ÙŠÙÙ‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§ ÙˆÙ†ÙÙƒØ± Ø³ÙˆÙŠÙ‹Ø§ Ø¨Ø­Ù„ÙˆÙ„ Ø¹Ù…Ù„ÙŠØ©."
        )
    if re.search(r"(Ø´ÙƒØ±Ø§|Ø«Ù†ÙƒÙŠÙˆ|thank|Ù…Ù…ØªØ§Ø²|Ø¬Ø²Ø§Ùƒ Ø§Ù„Ù„Ù‡ Ø®ÙŠØ±)", q, re.I):
        return "Ø´ÙƒØ±Ù‹Ø§ Ù„Ø°ÙˆÙ‚Ùƒ! ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø¯Ø§Ø¦Ù…Ù‹Ø§ ðŸ™"
    return None

# ===== Beauty Coach (Ø§Ù„Ø¹Ù†Ø§ÙŠØ© ÙˆØ§Ù„Ø¬Ù…Ø§Ù„) =====
BEAUTY_PAT = re.compile(
    r"(Ø¨Ø´Ø±Ù‡|Ø¨Ø´Ø±Ø©|ØªÙØªÙŠØ­|Ø¨ÙŠØ§Ø¶|ØºØ³ÙˆÙ„|Ø±ØªÙŠÙ†ÙˆÙ„|ÙÙŠØªØ§Ù…ÙŠÙ†|Ø´Ø¹Ø±|Ø·ÙˆÙ„ Ø´Ø¹Ø±|ØªØ³Ø§Ù‚Ø·|Ù‚Ø´Ø±Ù‡|Ø­Ø¨ Ø´Ø¨Ø§Ø¨|Ø­Ø¨ÙˆØ¨|Ø±Ø¤ÙˆØ³ Ø³ÙˆØ¯Ø§Ø¡|ØªØ±Ø·ÙŠØ¨|ÙˆØ§Ù‚ÙŠ|Ø±Ø´Ø§Ù‚Ù‡|ØªØ®Ø³ÙŠØ³|Ø±Ø¬ÙŠÙ…)",
    re.I
)

def beauty_coach(q: str) -> Optional[str]:
    if not BEAUTY_PAT.search(q):
        return None
    ql = q.lower()
    tips = []

    # Ø£Ø³Ø§Ø³ÙŠØ§Øª Ø¹Ø§Ù…Ø©
    base = [
        "ðŸ§¼ ØºØ³ÙˆÙ„ Ù„Ø·ÙŠÙ ØµØ¨Ø§Ø­Ù‹Ø§ ÙˆÙ…Ø³Ø§Ø¡Ù‹ (Ø¨Ø¯ÙˆÙ† Ø³Ù„ÙØ§Øª/ÙƒØ­ÙˆÙ„ Ù‚ÙˆÙŠ).",
        "ðŸ§´ ØªØ±Ø·ÙŠØ¨ ÙŠÙˆÙ…ÙŠ â€” Ø§Ù„Ø¨Ø´Ø±Ø© Ø§Ù„Ø¯Ù‡Ù†ÙŠØ© ØªØ­ØªØ§Ø¬ ØªØ±Ø·ÙŠØ¨ Ø£ÙŠØ¶Ù‹Ø§ (Ø¬Ù„/Ù„ÙˆØ´Ù† Ø®ÙÙŠÙ).",
        "ðŸ›¡ï¸ ÙˆØ§Ù‚ÙŠ Ø´Ù…Ø³ SPF 30+ ÙŠÙˆÙ…ÙŠÙ‹Ø§ â€” Ø£Ù‡Ù… Ø®Ø·ÙˆØ© Ù„ØªÙØªÙŠØ­ ÙˆØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¨ÙˆØ¨ ÙˆØ§Ù„Ø¢Ø«Ø§Ø±.",
        "ðŸ›Œ Ù†ÙˆÙ… ÙƒØ§ÙÙ ÙˆØ´Ø±Ø¨ Ù…Ø§Ø¡ Ø¨Ø§Ù†ØªØ¸Ø§Ù… â€” ÙŠØ¤Ø«Ø±Ø§Ù† Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¸Ù‡Ø±.",
    ]

    if re.search(r"(ØªÙØªÙŠØ­|Ø¨ÙŠØ§Ø¶|Ø§Ø³Ù…Ø±Ø§Ø±|ØºÙÙ…ÙÙˆÙ‚|ØºÙ…ÙˆÙ‚)", ql):
        tips += [
            "ÙÙŠØªØ§Ù…ÙŠÙ† C ØµØ¨Ø§Ø­Ù‹Ø§ (3â€“10%) + ÙˆØ§Ù‚ÙŠ Ø´Ù…Ø³ â€” ÙŠØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù„ÙˆÙ†.",
            "Ù†ÙŠØ§Ø³ÙŠÙ†Ø§Ù…ÙŠØ¯ 4â€“10% Ù…Ø³Ø§Ø¡Ù‹ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØµØ¨Øº ÙˆØ§Ù„Ù„Ù…Ø¹Ø§Ù†.",
            "ØªØ¬Ù†Ø¨ Ø®Ù„Ø·Ø§Øª Ù…Ø¬Ù‡ÙˆÙ„Ø©/Ù…ÙˆØ§Ø¯ Ù…Ø¨ÙŠØ¶Ø© Ù‚Ø§Ø³ÙŠØ©. Ø¥Ù† ÙˆÙØ¬Ø¯ ØªØµØ¨Øº Ø´Ø¯ÙŠØ¯ â†’ Ø±Ø§Ø¬ÙØ¹/ÙŠ Ù…Ø®ØªØµ Ø¬Ù„Ø¯ÙŠØ©.",
        ]
    if re.search(r"(Ø­Ø¨ Ø´Ø¨Ø§Ø¨|Ø§Ù„Ø­Ø¨ÙˆØ¨|Ø±Ø¤ÙˆØ³ Ø³ÙˆØ¯Ø§Ø¡|whitehead|blackhead)", ql):
        tips += [
            "Ø¨Ù†Ø²ÙˆÙŠÙ„ Ø¨ÙŠØ±ÙˆÙƒØ³ÙŠØ¯ 2.5â€“5% Ù„Ù„Ø­Ø¨ÙˆØ¨ Ø§Ù„Ù…Ù„ØªÙ‡Ø¨Ø© (Ù…ÙˆØ¶Ø¹ÙŠÙ‹Ø§ ÙˆØ¨ÙƒÙ…ÙŠØ© ØµØºÙŠØ±Ø©).",
            "Ø³Ø§Ù„ÙŠØ³ÙŠÙ„ÙŠÙƒ Ø£Ø³ÙŠØ¯ 0.5â€“2% Ù„Ù„Ø±Ø¤ÙˆØ³ Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡ ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§Ù….",
            "Ø§Ù„Ø±ÙŠØªÙŠÙ†ÙˆÙ„ ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§ Ù„ÙŠÙ„Ù‹Ø§ 1â€“2Ã— Ø¨Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ (Ø«Ù… Ø²ÙŠØ§Ø¯Ø© Ø­Ø³Ø¨ Ø§Ù„ØªØ­Ù…Ù„).",
            "ØºÙŠÙ‘Ø±/ÙŠ ØºØ·Ø§Ø¡ Ø§Ù„ÙˆØ³Ø§Ø¯Ø© Ø¨Ø§Ù†ØªØ¸Ø§Ù… ÙˆÙ‚Ù„Ù‘Ù„/ÙŠ Ø§Ù„Ù„Ù…Ø³ Ø¨Ø§Ù„ÙŠØ¯ÙŠÙ†.",
            "Ù„Ùˆ Ø­Ø¨ Ø´Ø¯ÙŠØ¯/Ù†Ø¯Ø¨Ø§Øª/Ø­Ù…Ù„ â€” Ø§Ù„Ø£ÙØ¶Ù„ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¬Ù„Ø¯ÙŠØ© Ù„Ø®ÙŠØ§Ø±Ø§Øª Ù…Ø«Ù„ Ø£Ø¯Ø§Ø¨Ø§Ù„ÙŠÙ†/Ø¥ÙŠØ²ÙˆØªØ±ÙŠØªÙŠÙ†ÙˆÙŠÙ† Ø¨Ø¥Ø´Ø±Ø§Ù Ø·Ø¨ÙŠ.",
        ]
    if re.search(r"(Ø´Ø¹Ø±|Ø·ÙˆÙ„ Ø´Ø¹Ø±|ØªØ³Ø§Ù‚Ø·|Ù‚Ø´Ø±Ù‡)", ql):
        tips += [
            "ØªØ¯Ù„ÙŠÙƒ ÙØ±ÙˆØ© Ø§Ù„Ø±Ø£Ø³ 5 Ø¯Ù‚Ø§Ø¦Ù‚ ÙŠÙˆÙ…ÙŠÙ‹Ø§ Ù„ØªØ­ÙÙŠØ² Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø¯Ù…ÙˆÙŠØ©.",
            "Ø²ÙŠÙˆØª Ø®ÙÙŠÙØ© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø·Ø±Ø§Ù (Ø£Ø±Ø¬Ø§Ù†/Ø¬ÙˆØ¬ÙˆØ¨Ø§) ÙˆÙ„ÙŠØ³ Ø¹Ù„Ù‰ Ø§Ù„ÙØ±ÙˆØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¯Ù‡Ù†ÙŠØ©.",
            "ØªØºØ°ÙŠØ©: Ø¨Ø±ÙˆØªÙŠÙ† ÙƒØ§ÙÙ ÙˆØ­Ø¯ÙŠØ¯ ÙˆÙÙŠØªØ§Ù…ÙŠÙ† D â€” Ù†Ù‚ØµÙ‡Ù… ÙŠØ³Ø¨Ø¨ ØªØ³Ø§Ù‚Ø·Ù‹Ø§.",
            "Ù‚Ø´Ø±Ø©ØŸ Ø¬Ø±Ù‘Ø¨/ÙŠ Ø´Ø§Ù…Ø¨Ùˆ ÙƒÙŠØªÙˆÙƒÙˆÙ†Ø§Ø²ÙˆÙ„ 2% Ù…Ø±ØªÙŠÙ† Ø£Ø³Ø¨ÙˆØ¹ÙŠÙ‹Ø§.",
            "ØªØ³Ø§Ù‚Ø· Ù…Ù„Ø­ÙˆØ¸/ÙØ±Ø§ØºØ§ØªØŸ ØªØ­Ø§Ù„ÙŠÙ„ (Ø­Ø¯ÙŠØ¯ØŒ ÙÙŠØªØ§Ù…ÙŠÙ† DØŒ ØºØ¯Ø©) Ø«Ù… Ù…Ø®ØªØµ Ø¬Ù„Ø¯ÙŠØ©.",
        ]
    if re.search(r"(Ø±Ø´Ø§Ù‚Ù‡|ØªØ®Ø³ÙŠØ³|ÙˆØ²Ù†|Ø³Ù…Ù†Ù‡|Ø³Ù…Ù†Ø©|Ø¯Ø§ÙŠØª|Ø±Ø¬ÙŠÙ…)", ql):
        tips += [
            "Ø§Ø¨Ø¯Ø£/Ø¦ÙŠ Ø¨Ø®Ø·ÙˆØ§Øª Ø«Ø§Ø¨ØªØ©: Ø¹Ø¬Ø² Ø­Ø±Ø§Ø±ÙŠ Ù…Ø¹ØªØ¯Ù„ (300â€“500 Ø³Ø¹Ø±/ÙŠÙˆÙ…).",
            "Ù„ÙˆØ­Ø© ÙˆØ¬Ø¨Ø©: Ù†ØµÙÙ‡Ø§ Ø®Ø¶Ø§Ø±ØŒ Ø±Ø¨Ø¹ Ø¨Ø±ÙˆØªÙŠÙ†ØŒ Ø±Ø¨Ø¹ Ù†Ø´ÙˆÙŠØ§Øª ÙƒØ§Ù…Ù„Ø©.",
            "Ù…Ø´ÙŠ Ø³Ø±ÙŠØ¹ 30 Ø¯Ù‚ÙŠÙ‚Ø© â€” 5 Ø£ÙŠØ§Ù…/Ø£Ø³Ø¨ÙˆØ¹ + Ù…Ù‚Ø§ÙˆÙ…Ø© Ø®ÙÙŠÙØ© Ù…Ø±ØªÙŠÙ†/Ø£Ø³Ø¨ÙˆØ¹.",
            "ØªØ¬Ù†Ù‘Ø¨/ÙŠ Ø§Ù„Ø­Ù…ÙŠØ§Øª Ø§Ù„Ù‚Ø§Ø³ÙŠØ©/Ø§Ù„Ù…Ø¯Ø±Ù‘Ø§Øª/Ø§Ù„Ù…ÙƒÙ…Ù‘Ù„Ø§Øª Ø§Ù„Ù…Ø¬Ù‡ÙˆÙ„Ø© â€” Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ø£ÙˆÙ„Ù‹Ø§.",
        ]

    if not tips:
        tips = base
    else:
        tips = base + tips

    closing = (
        "\n\nðŸ’¬ ØªØ°ÙƒÙŠØ± Ù„Ø·ÙŠÙ: Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© Ø£Ù‡Ù… Ù…Ù† Ø§Ù„ÙƒÙ…Ø§Ù„."
        " Ù„Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø¯ÙŠØ¯Ø©/Ø§Ù„Ø­Ù…Ù„/Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ù…Ø²Ù…Ù†Ø© â€” Ø§Ø³ØªØ´Ø±/ÙŠ Ù…Ø®ØªØµÙ‹Ø§."
    )

    return (
        "Ø£Ù†Ø§ Ù…Ø¹Ùƒ â€” Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© Ù†ÙˆØµÙ‘Ù„ Ù„Ø£Ø¬Ù…Ù„ Ù†ØªÙŠØ¬Ø© ØªÙ†Ø§Ø³Ø¨Ùƒ âœ¨\n"
        + "\n".join(f"â€¢ {t}" for t in tips[:10]) + closing
    )

# ===== Gemini Ø§Ø®ØªÙŠØ§Ø±ÙŠ =====
def answer_gemini(q: str) -> Optional[str]:
    if not GEMINI:
        return None
    try:
        resp = GEMINI.generate_content("Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙˆØ§Ø¶Ø­Ø© Ø¨Ø§Ø®ØªØµØ§Ø± ÙˆØ¯Ù‚Ø© ÙˆØ¨Ù†Ø¨Ø±Ø© ÙˆØ¯ÙˆØ¯Ø©:\n"+q)
        return (resp.text or "").strip()
    except Exception as e:
        return f"(ØªÙ†Ø¨ÙŠÙ‡ Gemini): {e}"

# ===== ÙˆÙŠØ¨ + ØªÙ„Ø®ÙŠØµ Ù…Ø­Ù„ÙŠ Ù…Ø¹ Ù…ØµØ§Ø¯Ø± =====
def answer_from_web(q: str) -> str:
    key = f"w:{q}"
    c = cache.get(key)
    if c: return c
    hits = ddg_text(q, n=5)
    contexts, cites = [], []
    for h in hits:
        url = h.get("href") or h.get("url")
        if not url: continue
        txt = fetch_clean(url)
        if txt:
            contexts.append(txt)
            cites.append(url)
    if not contexts:
        return "Ù„Ù… Ø£Ø¬Ø¯ Ù…ØµØ§Ø¯Ø± ÙƒØ§ÙÙŠØ© Ø§Ù„Ø¢Ù†. Ø¬Ø±Ù‘Ø¨/ÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØµÙŠØ§ØºØ©."
    blob = "\n\n".join(contexts)[:16000]
    summ = summarize_text(blob, max_sentences=6)
    ans = AR(summ) + ("\n\nØ§Ù„Ù…ØµØ§Ø¯Ø±:\n" + "\n".join(f"- {u}" for u in cites[:5]) if cites else "")
    cache.set(key, ans, expire=3600)
    return ans

# ===== Ø§Ù„Ù…ÙˆØ¬Ù‘Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ =====
def omni_answer(q: str) -> str:
    q = AR(q)
    if not q: return "Ø§ÙƒØªØ¨/ÙŠ Ø³Ø¤Ø§Ù„Ùƒ Ø£ÙˆÙ„Ù‹Ø§."

    # 0) ØªØ­ÙŠØ§Øª/Ù…Ø´Ø§Ø¹Ø± Ø£ÙˆÙ„Ù‹Ø§
    a = answer_empathy(q)
    if a: return a

    # 1) Ø£Ø¯ÙˆØ§Øª Ù…Ø­Ù„ÙŠØ© + Beauty + ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§
    for tool in (answer_math, answer_units_dates, beauty_coach, answer_wikipedia):
        a = tool(q)
        if a: return a

    # 2) Gemini (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    a = answer_gemini(q)
    if a: return a

    # 3) ÙˆÙŠØ¨ + ØªÙ„Ø®ÙŠØµ Ù…Ø­Ù„ÙŠ
    return answer_from_web(q)
