# omni_brain.py â€” Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª (Brain) ÙÙŠ Ù…Ø´Ø±ÙˆØ¹ Bassam App
# ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ„Ø®ÙŠØµ ÙˆØ§Ù„ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠ Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª RAG Ø£Ùˆ Ø§Ù„ÙˆÙŠØ¨

import re
from sumy.parsers.plaintext import PlainTextParser   # âœ… Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ØµØ­ÙŠØ­
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer


def clean_text(text: str) -> str:
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© ÙˆØ§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ©."""
    text = re.sub(r"\s+", " ", text or "").strip()
    return text


def summarize_text(text: str, sentences_count: int = 5, lang: str = "arabic") -> str:
    """ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ Ø¨Ø·Ø±ÙŠÙ‚Ø© TextRank."""
    try:
        parser = PlainTextParser.from_string(text, Tokenizer(lang))
        summarizer = TextRankSummarizer()
        summary = summarizer(parser.document, sentences_count)
        summarized = "\n".join([str(s) for s in summary]).strip()
        return summarized if summarized else text
    except Exception as e:
        print(f"[Brain summarize_text] âŒ Error: {e}")
        return text


def merge_contexts(contexts):
    """Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† RAG ÙÙŠ Ù†Øµ ÙˆØ§Ø­Ø¯ Ø·ÙˆÙŠÙ„ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„."""
    combined = ""
    for c in contexts:
        text = c.get("text", "")
        if text:
            combined += "\n" + clean_text(text)
    return combined.strip()


def answer(query: str, context: list[dict]) -> str:
    """
    Ø¯Ø§Ù„Ø© Ø±Ø¦ÙŠØ³ÙŠØ© ØªÙØ³ØªØ®Ø¯Ù… Ù…Ù† main.py
    - ØªØ£Ø®Ø° Ø§Ù„Ø³Ø¤Ø§Ù„ (query)
    - ÙˆØ³ÙŠØ§Ù‚Ø§Øª Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† RAG (context)
    - ØªÙØ±Ø¬Ø¹ Ø¥Ø¬Ø§Ø¨Ø© Ø°ÙƒÙŠØ© Ù…Ø®ØªØµØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    """
    try:
        # Ø¯Ù…Ø¬ Ø§Ù„Ø³ÙŠØ§Ù‚Ø§Øª ÙÙŠ Ù†Øµ ÙˆØ§Ø­Ø¯
        combined_context = merge_contexts(context)
        if not combined_context:
            return "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©."

        # ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ Ø£ÙˆÙ„Ù‹Ø§ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
        summary = summarize_text(combined_context, sentences_count=8)

        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÙ‚Ø±Ø© Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„
        pattern = re.compile(rf".{{0,100}}{re.escape(query)}.{{0,300}}", re.IGNORECASE)
        matches = pattern.findall(summary)
        if matches:
            extracted = " ".join(matches)
            extracted = clean_text(extracted)
            final_answer = summarize_text(extracted, sentences_count=3)
        else:
            final_answer = summarize_text(summary, sentences_count=5)

        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø±Ø¯ Ø§Ù„Ø£Ø®ÙŠØ±
        if len(final_answer) < 40:
            final_answer += "\n\nğŸ“˜ ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ØªØ§Ø­."

        return final_answer.strip()

    except Exception as e:
        print(f"[Brain answer] âŒ Error: {e}")
        return "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ù‹Ø§."
