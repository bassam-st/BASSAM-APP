import os, re, math, json, time
from datetime import datetime
from dateutil import parser as dateparser
from typing import List, Dict, Optional

import httpx
from bs4 import BeautifulSoup
from readability import Document
from duckduckgo_search import DDGS
from diskcache import Cache
from wikipedia import summary as wiki_summary

from sympy import sympify, diff, integrate
from sumy.parsers.plaintext import PlainTextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer

# ===== ุฅุนุฏุงุฏุงุช ุนุงูุฉ =====
UA = {"User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/124 Safari/537.36"}
cache = Cache(".cache")

# Gemini (ุงุฎุชูุงุฑู)
USE_GEMINI = bool(os.getenv("GEMINI_API_KEY"))
if USE_GEMINI:
    import google.generativeai as genai
    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    GEMINI = genai.GenerativeModel("gemini-1.5-flash")
else:
    GEMINI = None

# ===== ูุณุงุนุฏุงุช ูุตูุฉ =====
AR = lambda s: re.sub(r"\s+", " ", (s or "").strip())

# ===== ุชูุฎูุต ูุญูู =====
def summarize_text(text: str, max_sentences: int = 5) -> str:
    try:
        parser = PlainTextParser.from_string(text, Tokenizer("arabic"))
        summ = TextRankSummarizer()
        sents = summ(parser.document, max_sentences)
        return " ".join(str(s) for s in sents)
    except Exception:
        return text[:700]

# ===== ุจุญุซ ุงูููุจ =====
def ddg_text(q: str, n: int = 5) -> List[Dict]:
    with DDGS() as ddgs:
        return list(ddgs.text(q, region="xa-ar", safesearch="moderate", max_results=n) or [])

def fetch_clean(url: str, timeout: int = 12) -> str:
    try:
        r = httpx.get(url, headers=UA, timeout=timeout, follow_redirects=True)
        r.raise_for_status()
        doc = Document(r.text)
        html_clean = doc.summary()
        text = BeautifulSoup(html_clean, "lxml").get_text("\n", strip=True)
        return text[:8000]
    except Exception:
        return ""

# ===== ุฃุฏูุงุช ูุญููุฉ (ุฑูุงุถูุงุช/ูุญุฏุงุช/ุชูุงุฑูุฎ) =====
MATH_PAT = re.compile(r"[=+\-*/^()]|sin|cos|tan|log|sqrt|โซ|dx|dy|d/dx|ูุดุชูุฉ|ุชูุงูู", re.I)
CURRENCY = {"USD":1.0, "EUR":0.92, "SAR":3.75, "AED":3.67, "YER":250.0}

def answer_math(q: str) -> Optional[str]:
    if not MATH_PAT.search(q):
        return None
    try:
        s = q.replace("^", "**")
        expr = sympify(s)
        return f"ุงููุงุชุฌ ุงูุชูุฑูุจู: {expr.evalf()}"
    except Exception:
        if q.strip().startswith("ูุดุชูุฉ "):
            t = q.split("ูุดุชูุฉ ",1)[1]
            try: return f"ูุดุชูุฉ {t} = {diff(sympify(t))}"
            except: return "ูู ุฃููู ุงูุชุนุจูุฑ ูููุดุชูุฉ."
        if q.strip().startswith("ุชูุงูู "):
            t = q.split("ุชูุงูู ",1)[1]
            try: return f"ุชูุงูู {t} = {integrate(sympify(t))}"
            except: return "ูู ุฃููู ุงูุชุนุจูุฑ ููุชูุงูู."
        return None

def answer_units_dates(q: str) -> Optional[str]:
    # ุนููุฉ ุจุณูุทุฉ: "100 USD ุฅูู YER"
    m = re.search(r"(\d+[\.,]?\d*)\s*(USD|EUR|SAR|AED|YER)\s*(?:->|ุงูู|ุฅูู|to)\s*(USD|EUR|SAR|AED|YER)", q, re.I)
    if m:
        amount = float(m.group(1).replace(",", "."))
        src, dst = m.group(2).upper(), m.group(3).upper()
        usd = amount / CURRENCY[src]
        out = usd * CURRENCY[dst]
        return f"ุชูุฑูุจูุง: {amount} {src} โ {round(out,2)} {dst}"
    # ุชุงุฑูุฎ/ููุช ุจุณูุท: "ูุง ุชุงุฑูุฎ 3 ุฃูุงู ุจุนุฏ 2025-09-27"
    m2 = re.search(r"(\d+)\s*(ููู|ุฃูุงู|day|days)\s*(?:ุจุนุฏ|later|from)\s*([0-9\-/: ]+)", q, re.I)
    if m2:
        n = int(m2.group(1)); base = dateparser.parse(m2.group(3))
        if base:
            return (base + __import__('datetime').timedelta(days=n)).strftime("%Y-%m-%d %H:%M")
    return None

# ===== ููููุจูุฏูุง ูุตูุฑุฉ =====
def answer_wikipedia(q: str) -> Optional[str]:
    m = re.search(r"^(ูู ูู|ูู ูู|ูุง ูู|ูุงูู|ูุงูู)\s+(.+)$", q.strip(), re.I)
    topic = m.group(2) if m else None
    topic = topic or (q if len(q.split())<=6 else None)
    if not topic:
        return None
    try:
        s = wiki_summary(topic, sentences=3, auto_suggest=False, redirect=True)
        return AR(s)
    except Exception:
        return None

# ===== ูุดุงุนุฑ ูุชุญูุงุช (ุดุฎุตูุฉ ูุฏูุฏุฉ) =====
GREET_WORDS = [
    "ูุฑุญุจุง", "ูุฑุญุจุงู", "ุงููุงู", "ุฃููุงู", "ุงูุณูุงู ุนูููู", "ููุง", "ุตุจุงุญ ุงูุฎูุฑ", "ูุณุงุก ุงูุฎูุฑ",
    "ูุงู", "ููุงู", "ุงุฒูู", "ุดูููู", "ูููู"
]
FAREWELL_WORDS = ["ูุน ุงูุณูุงูุฉ", "ุฅูู ุงูููุงุก", "ุชุตุจุญ ุนูู ุฎูุฑ", "ุงุดููู ูุงุญูุงู", "ุจุงู"]

PERSONA_TAGLINES = [
    "ุฃูุง ุจุณูุงู ุงูุฐูู โ ููุง ุนุดุงู ุฃุณุงุนุฏู ุจุฎุทูุงุช ุจุณูุทุฉ ููุงุถุญุฉ โจ",
    "ุจุณูุงู ูุนู! ูุญููุง ุฎุทูุฉ ุจุฎุทูุฉ ูุจูุฏูุก ๐ช",
]

def answer_empathy(q: str) -> Optional[str]:
    for w in GREET_WORDS:
        if w in q:
            return (
                "ูุนูููู ุงูุณูุงู ูุฑุญูุฉ ุงููู โ ุฃููุงู ูุณููุงู! ๐\n"
                + PERSONA_TAGLINES[0]
            ) if "ุงูุณูุงู" in w else (
                "ูุฑุญุจูุง! ุณุนูุฏ ุจูุฌูุฏู ๐ค\n" + PERSONA_TAGLINES[1]
            )
    for w in FAREWELL_WORDS:
        if w in q:
            return "ูู ุญูุธ ุงููู! ุฅุฐุง ุงุญุชุฌุช ุฃู ุดูุก ุฃูุง ุญุงุถุฑ ุฏุงุฆููุง ๐"
    if re.search(r"(ุฃูุง ุญุฒูู|ุญุฒููู|ูุชุถุงูู|ูุชุถุงููุฉ|ูููุงู|ูููุงูู|ุฒุนูุงู)", q):
        return (
            "ุฃูุง ููุง ูุนู ๐ โ ุฎุฐ ููุณูุง ุนููููุงุ ููู ูู ูุง ุงูุฐู ูุฒุนุฌู ุฎุทูุฉ ุฎุทูุฉ."
            " ุฃุนุฏู ุฃููู ุณุฃููู ูุทูููุง ููุงุถุญูุง ููููุฑ ุณูููุง ุจุญููู ุนูููุฉ."
        )
    if re.search(r"(ุดูุฑุง|ุซูููู|thank|ููุชุงุฒ|ุฌุฒุงู ุงููู ุฎูุฑ)", q, re.I):
        return "ุดูุฑูุง ูุฐููู! ูุณุนุฏูู ุฃุณุงุนุฏู ุฏุงุฆููุง ๐"
    return None

# ===== Beauty Coach (ุงูุนูุงูุฉ ูุงูุฌูุงู) =====
BEAUTY_PAT = re.compile(
    r"(ุจุดุฑู|ุจุดุฑุฉ|ุชูุชูุญ|ุจูุงุถ|ุบุณูู|ุฑุชูููู|ููุชุงููู|ุดุนุฑ|ุทูู ุดุนุฑ|ุชุณุงูุท|ูุดุฑู|ุญุจ ุดุจุงุจ|ุญุจูุจ|ุฑุคูุณ ุณูุฏุงุก|ุชุฑุทูุจ|ูุงูู|ุฑุดุงูู|ุชุฎุณูุณ|ุฑุฌูู)",
    re.I
)

def beauty_coach(q: str) -> Optional[str]:
    if not BEAUTY_PAT.search(q):
        return None
    ql = q.lower()
    tips = []

    # ุฃุณุงุณูุงุช ุนุงูุฉ
    base = [
        "๐งผ ุบุณูู ูุทูู ุตุจุงุญูุง ููุณุงุกู (ุจุฏูู ุณููุงุช/ูุญูู ููู).",
        "๐งด ุชุฑุทูุจ ูููู โ ุงูุจุดุฑุฉ ุงูุฏูููุฉ ุชุญุชุงุฌ ุชุฑุทูุจ ุฃูุถูุง (ุฌู/ููุดู ุฎููู).",
        "๐ก๏ธ ูุงูู ุดูุณ SPF 30+ ูููููุง โ ุฃูู ุฎุทูุฉ ูุชูุชูุญ ูุชูููู ุงูุญุจูุจ ูุงูุขุซุงุฑ.",
        "๐ ููู ูุงูู ูุดุฑุจ ูุงุก ุจุงูุชุธุงู โ ูุคุซุฑุงู ูุจุงุดุฑุฉ ุนูู ุงููุธูุฑ.",
    ]

    if re.search(r"(ุชูุชูุญ|ุจูุงุถ|ุงุณูุฑุงุฑ|ุบููููู|ุบููู)", ql):
        tips += [
            "ููุชุงููู C ุตุจุงุญูุง (3โ10%) + ูุงูู ุดูุณ โ ูุณุงุนุฏ ุนูู ุชูุญูุฏ ุงูููู.",
            "ููุงุณููุงููุฏ 4โ10% ูุณุงุกู ูุชูููู ุงูุชุตุจุบ ูุงูููุนุงู.",
            "ุชุฌูุจ ุฎูุทุงุช ูุฌูููุฉ/ููุงุฏ ูุจูุถุฉ ูุงุณูุฉ. ุฅู ููุฌุฏ ุชุตุจุบ ุดุฏูุฏ โ ุฑุงุฌูุน/ู ูุฎุชุต ุฌูุฏูุฉ.",
        ]
    if re.search(r"(ุญุจ ุดุจุงุจ|ุงูุญุจูุจ|ุฑุคูุณ ุณูุฏุงุก|whitehead|blackhead)", ql):
        tips += [
            "ุจูุฒููู ุจูุฑููุณูุฏ 2.5โ5% ููุญุจูุจ ุงูููุชูุจุฉ (ููุถุนููุง ูุจูููุฉ ุตุบูุฑุฉ).",
            "ุณุงููุณูููู ุฃุณูุฏ 0.5โ2% ููุฑุคูุณ ุงูุณูุฏุงุก ูุชูุธูู ุงููุณุงู.",
            "ุงูุฑูุชูููู ุชุฏุฑูุฌููุง ููููุง 1โ2ร ุจุงูุฃุณุจูุน (ุซู ุฒูุงุฏุฉ ุญุณุจ ุงูุชุญูู).",
            "ุบููุฑ/ู ุบุทุงุก ุงููุณุงุฏุฉ ุจุงูุชุธุงู ููููู/ู ุงูููุณ ุจุงููุฏูู.",
            "ูู ุญุจ ุดุฏูุฏ/ูุฏุจุงุช/ุญูู โ ุงูุฃูุถู ูุฑุงุฌุนุฉ ุฌูุฏูุฉ ูุฎูุงุฑุงุช ูุซู ุฃุฏุงุจุงููู/ุฅูุฒูุชุฑูุชููููู ุจุฅุดุฑุงู ุทุจู.",
        ]
    if re.search(r"(ุดุนุฑ|ุทูู ุดุนุฑ|ุชุณุงูุท|ูุดุฑู)", ql):
        tips += [
            "ุชุฏููู ูุฑูุฉ ุงูุฑุฃุณ 5 ุฏูุงุฆู ูููููุง ูุชุญููุฒ ุงูุฏูุฑุฉ ุงูุฏูููุฉ.",
            "ุฒููุช ุฎูููุฉ ุนูู ุงูุฃุทุฑุงู (ุฃุฑุฌุงู/ุฌูุฌูุจุง) ูููุณ ุนูู ุงููุฑูุฉ ุฅุฐุง ูุงูุช ุฏูููุฉ.",
            "ุชุบุฐูุฉ: ุจุฑูุชูู ูุงูู ูุญุฏูุฏ ูููุชุงููู D โ ููุตูู ูุณุจุจ ุชุณุงูุทูุง.",
            "ูุดุฑุฉุ ุฌุฑูุจ/ู ุดุงูุจู ููุชููููุงุฒูู 2% ูุฑุชูู ุฃุณุจูุนููุง.",
            "ุชุณุงูุท ููุญูุธ/ูุฑุงุบุงุชุ ุชุญุงููู (ุญุฏูุฏุ ููุชุงููู Dุ ุบุฏุฉ) ุซู ูุฎุชุต ุฌูุฏูุฉ.",
        ]
    if re.search(r"(ุฑุดุงูู|ุชุฎุณูุณ|ูุฒู|ุณููู|ุณููุฉ|ุฏุงูุช|ุฑุฌูู)", ql):
        tips += [
            "ุงุจุฏุฃ/ุฆู ุจุฎุทูุงุช ุซุงุจุชุฉ: ุนุฌุฒ ุญุฑุงุฑู ูุนุชุฏู (300โ500 ุณุนุฑ/ููู).",
            "ููุญุฉ ูุฌุจุฉ: ูุตููุง ุฎุถุงุฑุ ุฑุจุน ุจุฑูุชููุ ุฑุจุน ูุดููุงุช ูุงููุฉ.",
            "ูุดู ุณุฑูุน 30 ุฏูููุฉ โ 5 ุฃูุงู/ุฃุณุจูุน + ููุงููุฉ ุฎูููุฉ ูุฑุชูู/ุฃุณุจูุน.",
            "ุชุฌููุจ/ู ุงูุญููุงุช ุงููุงุณูุฉ/ุงููุฏุฑูุงุช/ุงููููููุงุช ุงููุฌูููุฉ โ ุงูุณูุงูุฉ ุฃูููุง.",
        ]

    if not tips:
        tips = base
    else:
        tips = base + tips

    closing = (
        "\n\n๐ฌ ุชุฐููุฑ ูุทูู: ุงูุงุณุชูุฑุงุฑูุฉ ุฃูู ูู ุงูููุงู."
        " ููุญุงูุงุช ุงูุดุฏูุฏุฉ/ุงูุญูู/ุงูุฃุฏููุฉ ุงููุฒููุฉ โ ุงุณุชุดุฑ/ู ูุฎุชุตูุง."
    )

    return (
        "ุฃูุง ูุนู โ ุฎุทูุฉ ุจุฎุทูุฉ ููุตูู ูุฃุฌูู ูุชูุฌุฉ ุชูุงุณุจู โจ\n"
        + "\n".join(f"โข {t}" for t in tips[:10]) + closing
    )

# ===== Gemini ุงุฎุชูุงุฑู =====
def answer_gemini(q: str) -> Optional[str]:
    if not GEMINI:
        return None
    try:
        resp = GEMINI.generate_content("ุฃุฌุจ ุจุงูุนุฑุจูุฉ ุงููุงุถุญุฉ ุจุงุฎุชุตุงุฑ ูุฏูุฉ ูุจูุจุฑุฉ ูุฏูุฏุฉ:\n"+q)
        return (resp.text or "").strip()
    except Exception as e:
        return f"(ุชูุจูู Gemini): {e}"

# ===== ููุจ + ุชูุฎูุต ูุญูู ูุน ูุตุงุฏุฑ =====
def answer_from_web(q: str) -> str:
    key = f"w:{q}"
    c = cache.get(key)
    if c: return c
    hits = ddg_text(q, n=5)
    contexts, cites = [], []
    for h in hits:
        url = h.get("href") or h.get("url")
        if not url: continue
        txt = fetch_clean(url)
        if txt:
            contexts.append(txt)
            cites.append(url)
    if not contexts:
        return "ูู ุฃุฌุฏ ูุตุงุฏุฑ ูุงููุฉ ุงูุขู. ุฌุฑูุจ/ู ุฅุนุงุฏุฉ ุงูุตูุงุบุฉ."
    blob = "\n\n".join(contexts)[:16000]
    summ = summarize_text(blob, max_sentences=6)
    ans = AR(summ) + ("\n\nุงููุตุงุฏุฑ:\n" + "\n".join(f"- {u}" for u in cites[:5]) if cites else "")
    cache.set(key, ans, expire=3600)
    return ans

# ===== ุงูููุฌูู ุงูุฑุฆูุณู =====
def omni_answer(q: str) -> str:
    q = AR(q)
    if not q: return "ุงูุชุจ/ู ุณุคุงูู ุฃูููุง."

    # 0) ุชุญูุงุช/ูุดุงุนุฑ ุฃูููุง
    a = answer_empathy(q)
    if a: return a

    # 1) ุฃุฏูุงุช ูุญููุฉ + Beauty + ููููุจูุฏูุง
    for tool in (answer_math, answer_units_dates, beauty_coach, answer_wikipedia):
        a = tool(q)
        if a: return a

    # 2) Gemini (ุงุฎุชูุงุฑู)
    a = answer_gemini(q)
    if a: return a

    # 3) ููุจ + ุชูุฎูุต ูุญูู
    return answer_from_web(q)
